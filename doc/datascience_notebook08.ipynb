{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 事前準備：共通コードの実行\n",
    "* このノートブックに接続したら，まずは以下の2つの共通コード（コードAとコードB）を実行する\n",
    "* これらの共通コードを実行しないと，それ以降のコードが実行できないので注意する\n",
    "* また，コードAとコードBは，ノートブックに接続するたび毎回実行すること（ノートブックに接続中は，何度も実行する必要はない）\n",
    "* 共通コードの詳細についての説明は割愛する（簡単な説明は第2回の「[サンプルノートブック02](https://colab.research.google.com/github/yoshida-nu/lec_datascience/blob/main/doc/datascience_notebook02.ipynb)」を参照）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27115,
     "status": "ok",
     "timestamp": 1716689312959,
     "user": {
      "displayName": "Takahiro YOSHIDA",
      "userId": "00096252480874798687"
     },
     "user_tz": -540
    },
    "id": "3pAqkx-zbIU2",
    "outputId": "b4d1e387-8e66-426b-8183-225623aa6c06"
   },
   "outputs": [],
   "source": [
    "# コードA：日本語化ライブラリ導入\n",
    "! pip install japanize-matplotlib | tail -n 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 3722,
     "status": "ok",
     "timestamp": 1718943596154,
     "user": {
      "displayName": "Takahiro YOSHIDA",
      "userId": "00096252480874798687"
     },
     "user_tz": -540
    },
    "id": "SOfPe7UybRuo"
   },
   "outputs": [],
   "source": [
    "# コードB：共通事前処理\n",
    "\n",
    "# B1:余分なワーニングを非表示にする\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 必要ライブラリのimport\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import japanize_matplotlib # matplotlib日本語化対応\n",
    "import seaborn as sns\n",
    "\n",
    "# B2:データフレーム表示用関数\n",
    "from IPython.display import display\n",
    "\n",
    "# B3:表示オプション調整\n",
    "np.set_printoptions(suppress = True, precision = 3) #numpyの浮動小数点の表示精度\n",
    "pd.options.display.float_format = '{:.3f}'.format #pandasでの浮動小数点の表示精度\n",
    "pd.set_option('display.max_columns', None) #データフレームですべての列データを表示\n",
    "\n",
    "# B4:グラフのデフォルトフォント指定\n",
    "plt.rcParams['font.size'] = 14\n",
    "\n",
    "# 乱数の種\n",
    "random_seed = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ボストン住宅データ\n",
    "* 第6回「[サンプルノートブック06](https://colab.research.google.com/github/yoshida-nu/lec_datascience/blob/main/doc/datascience_notebook06.ipynb)」で使用で使用した1970年代後半におけるボストンの住宅価格データ\n",
    "* URL: https://bit.ly/4hwOUgx\n",
    "\n",
    "|**列名**| **意味** |\n",
    "|:--|:--|\n",
    "|CRIME| その地域の犯罪発生率（high / low / very_low） |\n",
    "|ZN| 25,000平方フィートを超える住居区画の占める割合（広い部屋の割合） |\n",
    "|INDUS| 非小売業が占める面積の割合 |\n",
    "|CHAS| チャールズ川の付近かどうかのダミー変数（1: 川周辺，0: それ以外） |\n",
    "|NOX| 窒素酸化物の濃度 |\n",
    "|RM| 1戸当たりの平均部屋数 |\n",
    "|AGE| 1940年より前に建てられた物件の割合（築年数が35～40年ほどの割合） |\n",
    "|DIS| ボストン市内の5つの雇用施設までの距離 |\n",
    "|RAD| 主要高速道路へのアクセスしやすさの指標 |\n",
    "|TAX| 10,000ドル当たりの固定資産税率 |\n",
    "|PTRATIO| その地域の教員1人当たりの生徒数 |\n",
    "|LSTAT| その地域の低所得者の割合 |\n",
    "|PRICE| その地域の住宅平均価格（1,000ドル単位） |\n",
    "  \n",
    "**［以下のコードの処理内容］**\n",
    "*  1行目: ファイルのURLを変数`url`に代入\n",
    "*  2行目: pandasの`read_csv`関数を使って，ファイルをDataFrameとして読み込んで，変数`df`に代入\n",
    "*  3行目: `display`関数を使ってデータ（`df`の内容）を表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIME</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>high</td>\n",
       "      <td>0.000</td>\n",
       "      <td>18.100</td>\n",
       "      <td>0</td>\n",
       "      <td>0.718</td>\n",
       "      <td>3.561</td>\n",
       "      <td>87.900</td>\n",
       "      <td>1.613</td>\n",
       "      <td>24.000</td>\n",
       "      <td>666</td>\n",
       "      <td>20.200</td>\n",
       "      <td>7.120</td>\n",
       "      <td>27.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>low</td>\n",
       "      <td>0.000</td>\n",
       "      <td>8.140</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.950</td>\n",
       "      <td>82.000</td>\n",
       "      <td>3.990</td>\n",
       "      <td>4.000</td>\n",
       "      <td>307</td>\n",
       "      <td>21.000</td>\n",
       "      <td>27.710</td>\n",
       "      <td>13.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>very_low</td>\n",
       "      <td>82.500</td>\n",
       "      <td>2.030</td>\n",
       "      <td>0</td>\n",
       "      <td>0.415</td>\n",
       "      <td>6.162</td>\n",
       "      <td>38.400</td>\n",
       "      <td>6.270</td>\n",
       "      <td>2.000</td>\n",
       "      <td>348</td>\n",
       "      <td>14.700</td>\n",
       "      <td>7.430</td>\n",
       "      <td>24.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>low</td>\n",
       "      <td>0.000</td>\n",
       "      <td>21.890</td>\n",
       "      <td>0</td>\n",
       "      <td>0.624</td>\n",
       "      <td>6.151</td>\n",
       "      <td>97.900</td>\n",
       "      <td>1.669</td>\n",
       "      <td>4.000</td>\n",
       "      <td>437</td>\n",
       "      <td>21.200</td>\n",
       "      <td>18.460</td>\n",
       "      <td>17.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>high</td>\n",
       "      <td>0.000</td>\n",
       "      <td>18.100</td>\n",
       "      <td>0</td>\n",
       "      <td>0.614</td>\n",
       "      <td>6.980</td>\n",
       "      <td>67.600</td>\n",
       "      <td>2.533</td>\n",
       "      <td>24.000</td>\n",
       "      <td>666</td>\n",
       "      <td>20.200</td>\n",
       "      <td>11.660</td>\n",
       "      <td>29.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>high</td>\n",
       "      <td>0.000</td>\n",
       "      <td>18.100</td>\n",
       "      <td>0</td>\n",
       "      <td>0.740</td>\n",
       "      <td>6.219</td>\n",
       "      <td>100.000</td>\n",
       "      <td>2.005</td>\n",
       "      <td>24.000</td>\n",
       "      <td>666</td>\n",
       "      <td>20.200</td>\n",
       "      <td>16.590</td>\n",
       "      <td>18.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>high</td>\n",
       "      <td>0.000</td>\n",
       "      <td>18.100</td>\n",
       "      <td>0</td>\n",
       "      <td>0.655</td>\n",
       "      <td>5.759</td>\n",
       "      <td>48.200</td>\n",
       "      <td>3.067</td>\n",
       "      <td>24.000</td>\n",
       "      <td>666</td>\n",
       "      <td>20.200</td>\n",
       "      <td>14.130</td>\n",
       "      <td>19.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>high</td>\n",
       "      <td>0.000</td>\n",
       "      <td>18.100</td>\n",
       "      <td>0</td>\n",
       "      <td>0.671</td>\n",
       "      <td>6.380</td>\n",
       "      <td>96.200</td>\n",
       "      <td>1.386</td>\n",
       "      <td>24.000</td>\n",
       "      <td>666</td>\n",
       "      <td>20.200</td>\n",
       "      <td>23.690</td>\n",
       "      <td>13.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>low</td>\n",
       "      <td>0.000</td>\n",
       "      <td>9.900</td>\n",
       "      <td>0</td>\n",
       "      <td>0.544</td>\n",
       "      <td>5.914</td>\n",
       "      <td>83.200</td>\n",
       "      <td>3.999</td>\n",
       "      <td>4.000</td>\n",
       "      <td>304</td>\n",
       "      <td>18.400</td>\n",
       "      <td>18.330</td>\n",
       "      <td>17.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>high</td>\n",
       "      <td>0.000</td>\n",
       "      <td>18.100</td>\n",
       "      <td>0</td>\n",
       "      <td>0.693</td>\n",
       "      <td>5.453</td>\n",
       "      <td>100.000</td>\n",
       "      <td>1.490</td>\n",
       "      <td>24.000</td>\n",
       "      <td>666</td>\n",
       "      <td>20.200</td>\n",
       "      <td>30.590</td>\n",
       "      <td>5.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CRIME     ZN  INDUS  CHAS   NOX    RM     AGE   DIS    RAD  TAX  \\\n",
       "0       high  0.000 18.100     0 0.718 3.561  87.900 1.613 24.000  666   \n",
       "1        low  0.000  8.140     0 0.538 5.950  82.000 3.990  4.000  307   \n",
       "2   very_low 82.500  2.030     0 0.415 6.162  38.400 6.270  2.000  348   \n",
       "3        low  0.000 21.890     0 0.624 6.151  97.900 1.669  4.000  437   \n",
       "4       high  0.000 18.100     0 0.614 6.980  67.600 2.533 24.000  666   \n",
       "..       ...    ...    ...   ...   ...   ...     ...   ...    ...  ...   \n",
       "95      high  0.000 18.100     0 0.740 6.219 100.000 2.005 24.000  666   \n",
       "96      high  0.000 18.100     0 0.655 5.759  48.200 3.067 24.000  666   \n",
       "97      high  0.000 18.100     0 0.671 6.380  96.200 1.386 24.000  666   \n",
       "98       low  0.000  9.900     0 0.544 5.914  83.200 3.999  4.000  304   \n",
       "99      high  0.000 18.100     0 0.693 5.453 100.000 1.490 24.000  666   \n",
       "\n",
       "    PTRATIO  LSTAT  PRICE  \n",
       "0    20.200  7.120 27.500  \n",
       "1    21.000 27.710 13.200  \n",
       "2    14.700  7.430 24.100  \n",
       "3    21.200 18.460 17.800  \n",
       "4    20.200 11.660 29.800  \n",
       "..      ...    ...    ...  \n",
       "95   20.200 16.590 18.400  \n",
       "96   20.200 14.130 19.900  \n",
       "97   20.200 23.690 13.100  \n",
       "98   18.400 18.330 17.800  \n",
       "99   20.200 30.590  5.000  \n",
       "\n",
       "[100 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "url = 'https://bit.ly/4hwOUgx'\n",
    "df = pd.read_csv(url)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 代表的な回帰モデル\n",
    "* 線形回帰モデル\n",
    ">* 最も基本的なモデルで説明変数と目的変数が線形関係にあると仮定\n",
    "* 多項式回帰モデル\n",
    ">* 線形回帰を拡張し，説明変数の高次の項を含めたモデル\n",
    ">* 線形回帰モデルの説明変数を2乗，3乗，… した変数や説明変数同士の積などを説明変数に含んだモデルとなる\n",
    ">* より複雑な非線形関係をモデル化できる\n",
    "* リッジ回帰モデル／ラッソ回帰モデル\n",
    ">* 線形回帰モデルと多項式回帰モデルは，回帰係数を求めるために最小化する損失関数を平均二乗誤差としている\n",
    ">* これに対して，リッジ回帰モデルやラッソ回帰モデルは，平均二乗誤差にに正則化項（後述）を加えたものを損失関数としている\n",
    ">* 過学習を起こしにくいモデルとなる\n",
    "* エラスティックネット（Elastic Net）モデル\n",
    ">* リッジ回帰とラッソ回帰の正則化項を組み合わせたモデル\n",
    "* 回帰木モデル\n",
    ">* 分類木の概念を回帰に応用したモデル\n",
    ">* 説明変数と目的変数の間の非線形関係もモデル化できる\n",
    ">* そのため，複雑なデータ構造に対応する柔軟性を持つ\n",
    ">* データのスケールの影響が少ないため，データの標準化を必要としない\n",
    ">* 変数間の複雑な関係を木構造で可視化できるため，人間が理解しやすい形でモデルを示すことができる\n",
    "* ランダムフォレスト回帰モデル\n",
    ">* 複数の回帰木を組み合わせたモデル\n",
    ">* 各回帰木の予測を平均化することで，モデルの精度を向上させる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bTB7BgX6Yi5H"
   },
   "source": [
    "# データの前処理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前処理の概要\n",
    "* まずは，多項式回帰モデルを考える\n",
    "* このモデルに合わせて以下の前処理を順に行う\n",
    ">* 学習に利用しないCRIM列を削除する（欠損値への対処を単純化するためでもある）\n",
    ">* 欠損値を算術平均に置き換える\n",
    ">* 外れ値を選択・削除する\n",
    ">* 目的変数と説明変数に分割\n",
    ">* 訓練データ（70％）とテストデータ（30%）に分割\n",
    ">* データの標準化\n",
    "* 本来は「訓練データ＆検証データ」と「テストデータ」に分割し，モデルをチューニングする作業も行うが，ここではチューニング作業を省略する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 列の削除／欠損値の対処／外れ値の削除\n",
    "* `drop`メソッドを用いて，CRIME列をDataFrameから削除 ⇒ `df.drop(['CRIM'], axis = 1)`\n",
    ">* `axis = 1`で行データを削除\n",
    "* 欠損値を算術平均に置き換える ⇒ `df.fillna(df.mean())`\n",
    ">* `mean`メソッドで求めた算術平均を引数として，`fillna`メソッドを呼び出す\n",
    "* `drop`メソッドで外れ値を削除 ⇒ `df.drop([76], axis = 0)`\n",
    ">* 第6回講義「線形回帰モデルの学習(2)」と同様に，インデックス76のデータを外れ値として削除する\n",
    ">* `axis = 0`で行データを削除\n",
    "  \n",
    "**［以下のコードの処理内容］**\n",
    "* 1～2行目: ファイルをDataFrameとして読み込み，変数`df`に代入\n",
    "* 3行目: `drop`メソッドで，`df`からCRIME列を削除し，その結果を`df`に代入\n",
    "* 4行目: `fillna`メソッドと`mean`メソッドを使って，`df`の欠損値を算術平均で穴埋めし，その結果を`df`に代入\n",
    "* 5行目: `drop`メソッドで，`df`から外れ値（インデックス76に対応する行データ）を削除し，その結果を`df`に代入\n",
    "* 6行目: `isnull`メソッドと`sum`メソッドを組み合わせて，各列の欠損値の数を計算して，`display`関数で表示する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "executionInfo": {
     "elapsed": 846,
     "status": "ok",
     "timestamp": 1716689330773,
     "user": {
      "displayName": "Takahiro YOSHIDA",
      "userId": "00096252480874798687"
     },
     "user_tz": -540
    },
    "id": "PquWcK03JaNa",
    "outputId": "7fe44825-4704-4d98-b144-58215e3cff33"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>欠損値の数</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ZN</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INDUS</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHAS</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOX</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RM</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGE</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIS</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAD</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAX</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PTRATIO</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTAT</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRICE</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         欠損値の数\n",
       "ZN           0\n",
       "INDUS        0\n",
       "CHAS         0\n",
       "NOX          0\n",
       "RM           0\n",
       "AGE          0\n",
       "DIS          0\n",
       "RAD          0\n",
       "TAX          0\n",
       "PTRATIO      0\n",
       "LSTAT        0\n",
       "PRICE        0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "url = 'https://bit.ly/4hwOUgx'\n",
    "df = pd.read_csv(url)\n",
    "df = df.drop(['CRIME'], axis = 1)\n",
    "df = df.fillna(df.mean())\n",
    "df = df.drop([76], axis = 0)\n",
    "display(pd.DataFrame(df.isnull().sum(), columns = ['欠損値の数']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 目的変数と説明変数に分割\n",
    "* `PRICE`を目的変数とする\n",
    "* 説明変数として，`RM`, `LSTAT`, `PTRATIO`を選択する\n",
    "* さらに，説明変数として選択した `RM`, `LSTAT`, `PTRATIO` から決まる以下の量を説明変数に加える\n",
    ">* `RM^2`: `RM`の2乗\n",
    ">* `LSTAT^2`：, `LSTAT`の2乗\n",
    ">* `PTRATIO^2`： `PTRATIO`の2乗\n",
    ">* `RM LSTAT`： `RM`と`LSTAT`の積\n",
    ">* `RM PTRATIO`： `RM`と`PTRATIO`の積\n",
    ">* `LSTAT PTRATIO`： `LSTAT`と`PTRATIO`の積\n",
    "* `RM LSTAT`, `RM PTRATIO`, `LSTAT PTRATIO` を交互作用項と呼ぶ\n",
    "* また，このモデルを次数が2（2次）の多項式回帰モデルと呼ぶ\n",
    "* 任意の次数の多項式回帰モデルの説明変数は，`sklearn`（scikit-learn）の`preprocessing`モジュールにおける，`PolynomialFeatures`クラスを利用することで簡単に作成できる\n",
    "  \n",
    "**［`PolynomialFeatures`クラスによる説明変数の作成手順］**\n",
    "* まず，多項式モデルの説明変数を生成するためのオブジェクトを`PolynomialFeatures`クラスから生成し，変数に代入する\n",
    "* 書式: `変数 = PolynomialFeatures(degree = 次数, include_bias = False)`  \n",
    ">* `include_bias`: 定数項を含む（`True`），含まない（`False`）を指定\n",
    ">* `include_bias = True`にすると，すべての値が1の列（定数項）を作成する\n",
    ">* `include_bias = False`は，この列を作成しないということになるが，モデルの学習において定数項を0にするという意味ではないことに注意する\n",
    "* 生成したオブジェクトの`fit_transform`メソッドに説明変数データを渡して呼び出す\n",
    "* 書式: `変数.fit_transform(元の説明変数データ)`\n",
    ">* 引数で指定した説明変数データに対して，次数に応じた説明変数データが生成される\n",
    ">* 戻り値のクラス（データ型）は ndarray\n",
    "  \n",
    "**［以下のコードの処理内容］**\n",
    "* 1～2行目: ファイルをDataFrameとして読み込み，変数`df`に代入\n",
    "* 3～5行目: 列の削除，欠損値の対処，外れ値の削除\n",
    "* 6行目: 説明変数の列名を要素とするリスト`['RM', 'PTRATIO', 'LSTAT']`を変数`x_cols`に代入\n",
    "* 7行目: 目的変数の列名（リスト）`['PRICE']`を変数`t_col`に代入\n",
    "* 8行目: DataFrame `df` から,`df[x_cols]`で，説明変数の列だけ取り出し変数`x`に代入\n",
    "* 9行目: DataFrame `df` から,`df[t_col]`で目的変数の列だけ取り出し変数`t`に代入\n",
    "* 10行目: `preprocessing`モジュールの`PolynomialFeatures`クラスの読み込み\n",
    "* 11行目: `PolynomialFeatures`クラスのオブジェクトを生成し，変数`pf`に代入\n",
    ">* `degree = 2`で，2次の多項式回帰モデルを指定\n",
    ">* `include_bias = False`で，定数項の列を作成しない\n",
    "* 12行目: `fit_transform`メソッドで，2次の多項式回帰モデルの説明変数データを生成し，変数`x`に代入\n",
    ">* 引数は3つの説明変数 `RM`, `PTRATIO`, `LSTAT` のデータ `x`\n",
    ">* このデータをもとに2次の多項式回帰モデルの説明変数データ（2次の項） `RM^2`, `LSTAT^2`, `PTRATIO^2`, `RM LSTAT`, `RM PTRATIO`, `LSTAT PTRATIO`を生成\n",
    "* 13行目: `DataFrame`関数で，`x`をDataFrameに変換し，その結果を変数`x`に代入\n",
    ">* `pf.get_feature_names_out()`で，2次の多項式回帰モデルの説明変数名を取り出し，DataFrameの列名（`columns`）として設定\n",
    "* 14行目: `display`関数で，`x`の内容を表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RM</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>RM^2</th>\n",
       "      <th>RM PTRATIO</th>\n",
       "      <th>RM LSTAT</th>\n",
       "      <th>PTRATIO^2</th>\n",
       "      <th>PTRATIO LSTAT</th>\n",
       "      <th>LSTAT^2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.561</td>\n",
       "      <td>20.200</td>\n",
       "      <td>7.120</td>\n",
       "      <td>12.681</td>\n",
       "      <td>71.932</td>\n",
       "      <td>25.354</td>\n",
       "      <td>408.040</td>\n",
       "      <td>143.824</td>\n",
       "      <td>50.694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.950</td>\n",
       "      <td>21.000</td>\n",
       "      <td>27.710</td>\n",
       "      <td>35.403</td>\n",
       "      <td>124.950</td>\n",
       "      <td>164.875</td>\n",
       "      <td>441.000</td>\n",
       "      <td>581.910</td>\n",
       "      <td>767.844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.162</td>\n",
       "      <td>14.700</td>\n",
       "      <td>7.430</td>\n",
       "      <td>37.970</td>\n",
       "      <td>90.581</td>\n",
       "      <td>45.784</td>\n",
       "      <td>216.090</td>\n",
       "      <td>109.221</td>\n",
       "      <td>55.205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.151</td>\n",
       "      <td>21.200</td>\n",
       "      <td>18.460</td>\n",
       "      <td>37.835</td>\n",
       "      <td>130.401</td>\n",
       "      <td>113.547</td>\n",
       "      <td>449.440</td>\n",
       "      <td>391.352</td>\n",
       "      <td>340.772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.980</td>\n",
       "      <td>20.200</td>\n",
       "      <td>11.660</td>\n",
       "      <td>48.720</td>\n",
       "      <td>140.996</td>\n",
       "      <td>81.387</td>\n",
       "      <td>408.040</td>\n",
       "      <td>235.532</td>\n",
       "      <td>135.956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>6.219</td>\n",
       "      <td>20.200</td>\n",
       "      <td>16.590</td>\n",
       "      <td>38.676</td>\n",
       "      <td>125.624</td>\n",
       "      <td>103.173</td>\n",
       "      <td>408.040</td>\n",
       "      <td>335.118</td>\n",
       "      <td>275.228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5.759</td>\n",
       "      <td>20.200</td>\n",
       "      <td>14.130</td>\n",
       "      <td>33.166</td>\n",
       "      <td>116.332</td>\n",
       "      <td>81.375</td>\n",
       "      <td>408.040</td>\n",
       "      <td>285.426</td>\n",
       "      <td>199.657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>6.380</td>\n",
       "      <td>20.200</td>\n",
       "      <td>23.690</td>\n",
       "      <td>40.704</td>\n",
       "      <td>128.876</td>\n",
       "      <td>151.142</td>\n",
       "      <td>408.040</td>\n",
       "      <td>478.538</td>\n",
       "      <td>561.216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5.914</td>\n",
       "      <td>18.400</td>\n",
       "      <td>18.330</td>\n",
       "      <td>34.975</td>\n",
       "      <td>108.818</td>\n",
       "      <td>108.404</td>\n",
       "      <td>338.560</td>\n",
       "      <td>337.272</td>\n",
       "      <td>335.989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5.453</td>\n",
       "      <td>20.200</td>\n",
       "      <td>30.590</td>\n",
       "      <td>29.735</td>\n",
       "      <td>110.151</td>\n",
       "      <td>166.807</td>\n",
       "      <td>408.040</td>\n",
       "      <td>617.918</td>\n",
       "      <td>935.748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RM  PTRATIO  LSTAT   RM^2  RM PTRATIO  RM LSTAT  PTRATIO^2  \\\n",
       "0  3.561   20.200  7.120 12.681      71.932    25.354    408.040   \n",
       "1  5.950   21.000 27.710 35.403     124.950   164.875    441.000   \n",
       "2  6.162   14.700  7.430 37.970      90.581    45.784    216.090   \n",
       "3  6.151   21.200 18.460 37.835     130.401   113.547    449.440   \n",
       "4  6.980   20.200 11.660 48.720     140.996    81.387    408.040   \n",
       "..   ...      ...    ...    ...         ...       ...        ...   \n",
       "94 6.219   20.200 16.590 38.676     125.624   103.173    408.040   \n",
       "95 5.759   20.200 14.130 33.166     116.332    81.375    408.040   \n",
       "96 6.380   20.200 23.690 40.704     128.876   151.142    408.040   \n",
       "97 5.914   18.400 18.330 34.975     108.818   108.404    338.560   \n",
       "98 5.453   20.200 30.590 29.735     110.151   166.807    408.040   \n",
       "\n",
       "    PTRATIO LSTAT  LSTAT^2  \n",
       "0         143.824   50.694  \n",
       "1         581.910  767.844  \n",
       "2         109.221   55.205  \n",
       "3         391.352  340.772  \n",
       "4         235.532  135.956  \n",
       "..            ...      ...  \n",
       "94        335.118  275.228  \n",
       "95        285.426  199.657  \n",
       "96        478.538  561.216  \n",
       "97        337.272  335.989  \n",
       "98        617.918  935.748  \n",
       "\n",
       "[99 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "url = 'https://bit.ly/4hwOUgx'\n",
    "df = pd.read_csv(url)\n",
    "df = df.drop(['CRIME'], axis = 1)\n",
    "df = df.fillna(df.mean())\n",
    "df = df.drop([76], axis = 0)\n",
    "x_cols = ['RM', 'PTRATIO', 'LSTAT']\n",
    "t_col = ['PRICE']\n",
    "x = df[x_cols]\n",
    "t = df[t_col]\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "pf = PolynomialFeatures(degree = 2, include_bias = False)\n",
    "x = pf.fit_transform(x)\n",
    "x = pd.DataFrame(x, columns = pf.get_feature_names_out())\n",
    "display(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 訓練データとテストデータに分割／データの標準化\n",
    "* 説明変数と目的変数に分割できたので，次に，訓練データとテストデータに分割し，データの標準化を行う\n",
    "* 分割と標準化の処理は第6回「[サンプルノートブック06](https://colab.research.google.com/github/yoshida-nu/lec_datascience/blob/main/doc/datascience_notebook06.ipynb)」のコードと同様\n",
    "  \n",
    "**［以下のコードの処理内容］**\n",
    "* 1～2行目: ファイルをDataFrameとして読み込み，変数`df`に代入\n",
    "* 3～5行目: 列の削除，欠損値の対処，外れ値の削除\n",
    "* 6～13行目: 説明変数と目的変数に分割し，変数`x`と`t`にそれぞれ代入\n",
    "* 14行目: `model_selection`モジュールの`train_test_split`関数の読み込み\n",
    "* 15行目: 説明変数と目的変数を訓練データ（70％）と検証データ（30％）に分割し，`x_train`, `x_test`, `t_train`, `t_test`にそれぞれ代入\n",
    "* 16行目: `preprocessing`モジュールの`StandardScaler`クラスの読み込み\n",
    "* 17行目: `StandardScaler`クラスのオブジェクトを生成し，変数`sc_x`に代入\n",
    "* 18行目: `sc_x`に対し，`fit`メソッドを適用する（引数は`x_train`）\n",
    "* 19行目: `sc_x`に対する`transform`メソッドで`x_train`を標準化し，その結果を変数`x_train_s`に代入\n",
    "* 20行目: `DataFrame`関数で，`x_train_s`をDataFrameに変換し，その結果を変数`x_train_s`に代入\n",
    "* 21行目: `sc_x`に対する`transform`メソッドで`x_test`を標準化し，その結果を変数`x_test_s`に代入\n",
    "* 22行目: `DataFrame`関数で，`x_test_s`をDataFrameに変換し，その結果を変数`x_test_s`に代入\n",
    "* 23行目: `StandardScaler`クラスのオブジェクトを生成し，変数`sc_t`に代入\n",
    "* 24行目: `sc_t`に対し，`fit`メソッドを適用する（引数は`t_train`）\n",
    "* 25行目: `sc_t`に対する`transform`メソッドで`t_train`を標準化し，その結果を変数`t_train_s`に代入\n",
    "* 26行目: `DataFrame`関数で，`t_train_s`をDataFrameに変換し，その結果を変数`t_train_s`に代入\n",
    "* 27行目: `sc_t`に対する`transform`メソッドで`t_test`を標準化し，その結果を変数`t_test_s`に代入\n",
    "* 28行目: `DataFrame`関数で，`t_test_s`をDataFrameに変換し，その結果を変数`t_test_s`に代入\n",
    "* 29～36行目: `x_train_s`, `x_test_s`, `t_train_s`, `t_test_s`の内容をそれぞれ表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ x_train_s ================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RM</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>RM^2</th>\n",
       "      <th>RM PTRATIO</th>\n",
       "      <th>RM LSTAT</th>\n",
       "      <th>PTRATIO^2</th>\n",
       "      <th>PTRATIO LSTAT</th>\n",
       "      <th>LSTAT^2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.503</td>\n",
       "      <td>1.182</td>\n",
       "      <td>0.641</td>\n",
       "      <td>-0.523</td>\n",
       "      <td>0.566</td>\n",
       "      <td>0.613</td>\n",
       "      <td>1.248</td>\n",
       "      <td>0.861</td>\n",
       "      <td>0.388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.306</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.497</td>\n",
       "      <td>0.245</td>\n",
       "      <td>-0.601</td>\n",
       "      <td>-0.437</td>\n",
       "      <td>-1.036</td>\n",
       "      <td>-0.628</td>\n",
       "      <td>-0.559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.461</td>\n",
       "      <td>-1.963</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>-0.485</td>\n",
       "      <td>-2.084</td>\n",
       "      <td>-0.089</td>\n",
       "      <td>-1.878</td>\n",
       "      <td>-0.422</td>\n",
       "      <td>-0.244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.131</td>\n",
       "      <td>0.015</td>\n",
       "      <td>2.644</td>\n",
       "      <td>-1.071</td>\n",
       "      <td>-1.032</td>\n",
       "      <td>2.353</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>2.436</td>\n",
       "      <td>3.398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.859</td>\n",
       "      <td>-0.340</td>\n",
       "      <td>0.599</td>\n",
       "      <td>-0.839</td>\n",
       "      <td>-1.061</td>\n",
       "      <td>0.459</td>\n",
       "      <td>-0.401</td>\n",
       "      <td>0.445</td>\n",
       "      <td>0.344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.187</td>\n",
       "      <td>-0.847</td>\n",
       "      <td>-0.758</td>\n",
       "      <td>0.127</td>\n",
       "      <td>-0.562</td>\n",
       "      <td>-0.753</td>\n",
       "      <td>-0.894</td>\n",
       "      <td>-0.827</td>\n",
       "      <td>-0.699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>-0.426</td>\n",
       "      <td>0.827</td>\n",
       "      <td>-0.128</td>\n",
       "      <td>-0.453</td>\n",
       "      <td>0.344</td>\n",
       "      <td>-0.174</td>\n",
       "      <td>0.840</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>-0.118</td>\n",
       "      <td>1.233</td>\n",
       "      <td>-0.491</td>\n",
       "      <td>-0.166</td>\n",
       "      <td>1.026</td>\n",
       "      <td>-0.504</td>\n",
       "      <td>1.307</td>\n",
       "      <td>-0.316</td>\n",
       "      <td>-0.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>-0.277</td>\n",
       "      <td>-1.709</td>\n",
       "      <td>0.151</td>\n",
       "      <td>-0.315</td>\n",
       "      <td>-1.722</td>\n",
       "      <td>0.158</td>\n",
       "      <td>-1.667</td>\n",
       "      <td>-0.232</td>\n",
       "      <td>-0.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>-0.071</td>\n",
       "      <td>-0.390</td>\n",
       "      <td>0.132</td>\n",
       "      <td>-0.122</td>\n",
       "      <td>-0.378</td>\n",
       "      <td>0.190</td>\n",
       "      <td>-0.451</td>\n",
       "      <td>0.016</td>\n",
       "      <td>-0.103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       RM  PTRATIO  LSTAT   RM^2  RM PTRATIO  RM LSTAT  PTRATIO^2  \\\n",
       "0  -0.503    1.182  0.641 -0.523       0.566     0.613      1.248   \n",
       "1   0.306   -0.999 -0.497  0.245      -0.601    -0.437     -1.036   \n",
       "2  -0.461   -1.963 -0.039 -0.485      -2.084    -0.089     -1.878   \n",
       "3  -1.131    0.015  2.644 -1.071      -1.032     2.353     -0.039   \n",
       "4  -0.859   -0.340  0.599 -0.839      -1.061     0.459     -0.401   \n",
       "..    ...      ...    ...    ...         ...       ...        ...   \n",
       "64  0.187   -0.847 -0.758  0.127      -0.562    -0.753     -0.894   \n",
       "65 -0.426    0.827 -0.128 -0.453       0.344    -0.174      0.840   \n",
       "66 -0.118    1.233 -0.491 -0.166       1.026    -0.504      1.307   \n",
       "67 -0.277   -1.709  0.151 -0.315      -1.722     0.158     -1.667   \n",
       "68 -0.071   -0.390  0.132 -0.122      -0.378     0.190     -0.451   \n",
       "\n",
       "    PTRATIO LSTAT  LSTAT^2  \n",
       "0           0.861    0.388  \n",
       "1          -0.628   -0.559  \n",
       "2          -0.422   -0.244  \n",
       "3           2.436    3.398  \n",
       "4           0.445    0.344  \n",
       "..            ...      ...  \n",
       "64         -0.827   -0.699  \n",
       "65         -0.005   -0.313  \n",
       "66         -0.316   -0.556  \n",
       "67         -0.232   -0.088  \n",
       "68          0.016   -0.103  \n",
       "\n",
       "[69 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ t_train_s ================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>-0.214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>-0.214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>-0.418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    PRICE\n",
       "0  -0.346\n",
       "1   0.146\n",
       "2  -0.394\n",
       "3   0.157\n",
       "4  -0.358\n",
       "..    ...\n",
       "64  0.026\n",
       "65 -0.214\n",
       "66 -0.214\n",
       "67 -0.418\n",
       "68  0.865\n",
       "\n",
       "[69 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ x_test_s ================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RM</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>RM^2</th>\n",
       "      <th>RM PTRATIO</th>\n",
       "      <th>RM LSTAT</th>\n",
       "      <th>PTRATIO^2</th>\n",
       "      <th>PTRATIO LSTAT</th>\n",
       "      <th>LSTAT^2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.455</td>\n",
       "      <td>-1.963</td>\n",
       "      <td>2.455</td>\n",
       "      <td>-1.336</td>\n",
       "      <td>-2.838</td>\n",
       "      <td>1.996</td>\n",
       "      <td>-1.878</td>\n",
       "      <td>1.413</td>\n",
       "      <td>3.043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.057</td>\n",
       "      <td>0.827</td>\n",
       "      <td>-0.237</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.847</td>\n",
       "      <td>-0.190</td>\n",
       "      <td>0.840</td>\n",
       "      <td>-0.115</td>\n",
       "      <td>-0.391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.492</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-1.065</td>\n",
       "      <td>0.431</td>\n",
       "      <td>-0.441</td>\n",
       "      <td>-1.070</td>\n",
       "      <td>-1.036</td>\n",
       "      <td>-1.100</td>\n",
       "      <td>-0.826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.827</td>\n",
       "      <td>0.143</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.269</td>\n",
       "      <td>-0.094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.286</td>\n",
       "      <td>0.827</td>\n",
       "      <td>2.198</td>\n",
       "      <td>-1.199</td>\n",
       "      <td>-0.554</td>\n",
       "      <td>1.843</td>\n",
       "      <td>0.840</td>\n",
       "      <td>2.347</td>\n",
       "      <td>2.581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.375</td>\n",
       "      <td>-0.593</td>\n",
       "      <td>-0.908</td>\n",
       "      <td>1.368</td>\n",
       "      <td>0.739</td>\n",
       "      <td>-0.778</td>\n",
       "      <td>-0.651</td>\n",
       "      <td>-0.930</td>\n",
       "      <td>-0.766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.237</td>\n",
       "      <td>-0.390</td>\n",
       "      <td>-0.724</td>\n",
       "      <td>2.363</td>\n",
       "      <td>1.743</td>\n",
       "      <td>-0.418</td>\n",
       "      <td>-0.451</td>\n",
       "      <td>-0.746</td>\n",
       "      <td>-0.682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.143</td>\n",
       "      <td>0.218</td>\n",
       "      <td>-0.853</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.377</td>\n",
       "      <td>-0.866</td>\n",
       "      <td>0.174</td>\n",
       "      <td>-0.799</td>\n",
       "      <td>-0.742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.331</td>\n",
       "      <td>-0.390</td>\n",
       "      <td>-1.200</td>\n",
       "      <td>2.477</td>\n",
       "      <td>1.830</td>\n",
       "      <td>-1.071</td>\n",
       "      <td>-0.451</td>\n",
       "      <td>-1.171</td>\n",
       "      <td>-0.869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.927</td>\n",
       "      <td>-0.593</td>\n",
       "      <td>-1.277</td>\n",
       "      <td>3.218</td>\n",
       "      <td>2.133</td>\n",
       "      <td>-1.133</td>\n",
       "      <td>-0.651</td>\n",
       "      <td>-1.251</td>\n",
       "      <td>-0.890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.343</td>\n",
       "      <td>-0.898</td>\n",
       "      <td>0.178</td>\n",
       "      <td>-0.376</td>\n",
       "      <td>-1.068</td>\n",
       "      <td>0.171</td>\n",
       "      <td>-0.941</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.491</td>\n",
       "      <td>0.827</td>\n",
       "      <td>-1.072</td>\n",
       "      <td>0.430</td>\n",
       "      <td>1.299</td>\n",
       "      <td>-1.077</td>\n",
       "      <td>0.840</td>\n",
       "      <td>-0.959</td>\n",
       "      <td>-0.828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.257</td>\n",
       "      <td>-0.086</td>\n",
       "      <td>-0.295</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.207</td>\n",
       "      <td>-0.215</td>\n",
       "      <td>-0.144</td>\n",
       "      <td>-0.317</td>\n",
       "      <td>-0.431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.517</td>\n",
       "      <td>0.320</td>\n",
       "      <td>-0.134</td>\n",
       "      <td>-0.536</td>\n",
       "      <td>-0.184</td>\n",
       "      <td>-0.201</td>\n",
       "      <td>0.282</td>\n",
       "      <td>-0.099</td>\n",
       "      <td>-0.317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.080</td>\n",
       "      <td>0.269</td>\n",
       "      <td>-1.341</td>\n",
       "      <td>1.046</td>\n",
       "      <td>1.349</td>\n",
       "      <td>-1.353</td>\n",
       "      <td>0.228</td>\n",
       "      <td>-1.261</td>\n",
       "      <td>-0.906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.871</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.123</td>\n",
       "      <td>-0.849</td>\n",
       "      <td>-0.658</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.119</td>\n",
       "      <td>-0.111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.710</td>\n",
       "      <td>-0.847</td>\n",
       "      <td>0.022</td>\n",
       "      <td>-0.709</td>\n",
       "      <td>-1.345</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>-0.894</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>-0.195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.316</td>\n",
       "      <td>-0.289</td>\n",
       "      <td>-1.335</td>\n",
       "      <td>2.458</td>\n",
       "      <td>1.931</td>\n",
       "      <td>-1.261</td>\n",
       "      <td>-0.350</td>\n",
       "      <td>-1.285</td>\n",
       "      <td>-0.904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-2.955</td>\n",
       "      <td>0.827</td>\n",
       "      <td>1.693</td>\n",
       "      <td>-2.418</td>\n",
       "      <td>-2.294</td>\n",
       "      <td>0.619</td>\n",
       "      <td>0.840</td>\n",
       "      <td>1.836</td>\n",
       "      <td>1.756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.338</td>\n",
       "      <td>0.320</td>\n",
       "      <td>-0.330</td>\n",
       "      <td>-0.372</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>-0.371</td>\n",
       "      <td>0.282</td>\n",
       "      <td>-0.287</td>\n",
       "      <td>-0.455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.058</td>\n",
       "      <td>-1.963</td>\n",
       "      <td>-0.744</td>\n",
       "      <td>-0.109</td>\n",
       "      <td>-1.778</td>\n",
       "      <td>-0.772</td>\n",
       "      <td>-1.878</td>\n",
       "      <td>-0.941</td>\n",
       "      <td>-0.692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.504</td>\n",
       "      <td>0.320</td>\n",
       "      <td>-0.539</td>\n",
       "      <td>-0.524</td>\n",
       "      <td>-0.171</td>\n",
       "      <td>-0.621</td>\n",
       "      <td>0.282</td>\n",
       "      <td>-0.487</td>\n",
       "      <td>-0.584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.317</td>\n",
       "      <td>-0.593</td>\n",
       "      <td>-0.098</td>\n",
       "      <td>-0.353</td>\n",
       "      <td>-0.781</td>\n",
       "      <td>-0.118</td>\n",
       "      <td>-0.651</td>\n",
       "      <td>-0.224</td>\n",
       "      <td>-0.289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.299</td>\n",
       "      <td>0.827</td>\n",
       "      <td>0.419</td>\n",
       "      <td>0.237</td>\n",
       "      <td>1.099</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.548</td>\n",
       "      <td>0.160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.187</td>\n",
       "      <td>1.233</td>\n",
       "      <td>0.115</td>\n",
       "      <td>-0.231</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.143</td>\n",
       "      <td>1.307</td>\n",
       "      <td>0.321</td>\n",
       "      <td>-0.118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.612</td>\n",
       "      <td>0.320</td>\n",
       "      <td>-1.162</td>\n",
       "      <td>0.554</td>\n",
       "      <td>0.936</td>\n",
       "      <td>-1.172</td>\n",
       "      <td>0.282</td>\n",
       "      <td>-1.086</td>\n",
       "      <td>-0.858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.267</td>\n",
       "      <td>-0.035</td>\n",
       "      <td>-0.408</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.263</td>\n",
       "      <td>-0.342</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>-0.414</td>\n",
       "      <td>-0.505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.481</td>\n",
       "      <td>0.015</td>\n",
       "      <td>-0.698</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.515</td>\n",
       "      <td>-0.642</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>-0.676</td>\n",
       "      <td>-0.669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.815</td>\n",
       "      <td>-2.826</td>\n",
       "      <td>-1.398</td>\n",
       "      <td>1.865</td>\n",
       "      <td>-1.295</td>\n",
       "      <td>-1.379</td>\n",
       "      <td>-2.545</td>\n",
       "      <td>-1.463</td>\n",
       "      <td>-0.918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-1.073</td>\n",
       "      <td>0.827</td>\n",
       "      <td>2.803</td>\n",
       "      <td>-1.021</td>\n",
       "      <td>-0.331</td>\n",
       "      <td>2.542</td>\n",
       "      <td>0.840</td>\n",
       "      <td>2.959</td>\n",
       "      <td>3.711</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       RM  PTRATIO  LSTAT   RM^2  RM PTRATIO  RM LSTAT  PTRATIO^2  \\\n",
       "0  -1.455   -1.963  2.455 -1.336      -2.838     1.996     -1.878   \n",
       "1   0.057    0.827 -0.237  0.001       0.847    -0.190      0.840   \n",
       "2   0.492   -0.999 -1.065  0.431      -0.441    -1.070     -1.036   \n",
       "3   0.010    0.827  0.143 -0.045       0.797     0.222      0.840   \n",
       "4  -1.286    0.827  2.198 -1.199      -0.554     1.843      0.840   \n",
       "5   1.375   -0.593 -0.908  1.368       0.739    -0.778     -0.651   \n",
       "6   2.237   -0.390 -0.724  2.363       1.743    -0.418     -0.451   \n",
       "7   0.143    0.218 -0.853  0.084       0.377    -0.866      0.174   \n",
       "8   2.331   -0.390 -1.200  2.477       1.830    -1.071     -0.451   \n",
       "9   2.927   -0.593 -1.277  3.218       2.133    -1.133     -0.651   \n",
       "10 -0.343   -0.898  0.178 -0.376      -1.068     0.171     -0.941   \n",
       "11  0.491    0.827 -1.072  0.430       1.299    -1.077      0.840   \n",
       "12  0.257   -0.086 -0.295  0.196       0.207    -0.215     -0.144   \n",
       "13 -0.517    0.320 -0.134 -0.536      -0.184    -0.201      0.282   \n",
       "14  1.080    0.269 -1.341  1.046       1.349    -1.353      0.228   \n",
       "15 -0.871    0.168  0.123 -0.849      -0.658    -0.020      0.120   \n",
       "16 -0.710   -0.847  0.022 -0.709      -1.345    -0.083     -0.894   \n",
       "17  2.316   -0.289 -1.335  2.458       1.931    -1.261     -0.350   \n",
       "18 -2.955    0.827  1.693 -2.418      -2.294     0.619      0.840   \n",
       "19 -0.338    0.320 -0.330 -0.372      -0.006    -0.371      0.282   \n",
       "20 -0.058   -1.963 -0.744 -0.109      -1.778    -0.772     -1.878   \n",
       "21 -0.504    0.320 -0.539 -0.524      -0.171    -0.621      0.282   \n",
       "22 -0.317   -0.593 -0.098 -0.353      -0.781    -0.118     -0.651   \n",
       "23  0.299    0.827  0.419  0.237       1.099     0.611      0.840   \n",
       "24 -0.187    1.233  0.115 -0.231       0.952     0.143      1.307   \n",
       "25  0.612    0.320 -1.162  0.554       0.936    -1.172      0.282   \n",
       "26  0.267   -0.035 -0.408  0.206       0.263    -0.342     -0.092   \n",
       "27  0.481    0.015 -0.698  0.420       0.515    -0.642     -0.039   \n",
       "28  1.815   -2.826 -1.398  1.865      -1.295    -1.379     -2.545   \n",
       "29 -1.073    0.827  2.803 -1.021      -0.331     2.542      0.840   \n",
       "\n",
       "    PTRATIO LSTAT  LSTAT^2  \n",
       "0           1.413    3.043  \n",
       "1          -0.115   -0.391  \n",
       "2          -1.100   -0.826  \n",
       "3           0.269   -0.094  \n",
       "4           2.347    2.581  \n",
       "5          -0.930   -0.766  \n",
       "6          -0.746   -0.682  \n",
       "7          -0.799   -0.742  \n",
       "8          -1.171   -0.869  \n",
       "9          -1.251   -0.890  \n",
       "10         -0.046   -0.063  \n",
       "11         -0.959   -0.828  \n",
       "12         -0.317   -0.431  \n",
       "13         -0.099   -0.317  \n",
       "14         -1.261   -0.906  \n",
       "15          0.119   -0.111  \n",
       "16         -0.168   -0.195  \n",
       "17         -1.285   -0.904  \n",
       "18          1.836    1.756  \n",
       "19         -0.287   -0.455  \n",
       "20         -0.941   -0.692  \n",
       "21         -0.487   -0.584  \n",
       "22         -0.224   -0.289  \n",
       "23          0.548    0.160  \n",
       "24          0.321   -0.118  \n",
       "25         -1.086   -0.858  \n",
       "26         -0.414   -0.505  \n",
       "27         -0.676   -0.669  \n",
       "28         -1.463   -0.918  \n",
       "29          2.959    3.711  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ t_test_s ================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-1.258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2.532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-2.086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PRICE\n",
       "0  -0.550\n",
       "1   0.074\n",
       "2   0.841\n",
       "3  -0.118\n",
       "4  -1.438\n",
       "5   1.105\n",
       "6   2.089\n",
       "7   0.289\n",
       "8   3.312\n",
       "9   3.108\n",
       "10 -0.322\n",
       "11 -0.058\n",
       "12  0.086\n",
       "13 -0.286\n",
       "14  0.865\n",
       "15 -0.598\n",
       "16 -0.634\n",
       "17  2.568\n",
       "18 -1.258\n",
       "19  0.277\n",
       "20  0.205\n",
       "21 -0.166\n",
       "22  0.229\n",
       "23 -0.682\n",
       "24 -0.946\n",
       "25  0.661\n",
       "26  0.181\n",
       "27  0.241\n",
       "28  2.532\n",
       "29 -2.086"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "url = 'https://bit.ly/4hwOUgx'\n",
    "df = pd.read_csv(url)\n",
    "df = df.drop(['CRIME'], axis = 1)\n",
    "df = df.fillna(df.mean())\n",
    "df = df.drop([76], axis = 0)\n",
    "x_cols = ['RM', 'PTRATIO', 'LSTAT']\n",
    "t_col = ['PRICE']\n",
    "x = df[x_cols]\n",
    "t = df[t_col]\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "pf = PolynomialFeatures(degree = 2, include_bias = False)\n",
    "x = pf.fit_transform(x)\n",
    "x = pd.DataFrame(x, columns = pf.get_feature_names_out())\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, t_train, t_test = train_test_split(x, t, test_size = 0.3, random_state = random_seed)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_x = StandardScaler()\n",
    "sc_x.fit(x_train)\n",
    "x_train_s = sc_x.transform(x_train)\n",
    "x_train_s = pd.DataFrame(x_train_s, columns = x_train.columns)\n",
    "x_test_s = sc_x.transform(x_test)\n",
    "x_test_s = pd.DataFrame(x_test_s, columns = x_test.columns)\n",
    "sc_t = StandardScaler()\n",
    "sc_t.fit(t_train)\n",
    "t_train_s = sc_t.transform(t_train)\n",
    "t_train_s = pd.DataFrame(t_train_s, columns = t_train.columns)\n",
    "t_test_s = sc_t.transform(t_test)\n",
    "t_test_s = pd.DataFrame(t_test_s, columns = t_test.columns)\n",
    "print('================ x_train_s ================')\n",
    "display(x_train_s)\n",
    "print('================ t_train_s ================')\n",
    "display(pd.DataFrame(t_train_s))\n",
    "print('================ x_test_s ================')\n",
    "display(x_test_s)\n",
    "print('================ t_test_s ================')\n",
    "display(pd.DataFrame(t_test_s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T8alCl897vEK"
   },
   "source": [
    "# 多項式回帰モデルの学習と評価\n",
    "* 以下のコードで，前処理したボストン住宅データで多項式回帰モデルの学習と評価\n",
    "* 学習と評価（一連の分析）の処理は第6回「[サンプルノートブック06](https://colab.research.google.com/github/yoshida-nu/lec_datascience/blob/main/doc/datascience_notebook06.ipynb)」のコードと同様\n",
    "* ただし，予測の処理は除く\n",
    "* 実行結果の決定係数をみると，テストデータに対する決定係数は，訓練データに対する決定係数よりも小さくなっており，過学習が発生している\n",
    ">* これを過学習と判断するかは分析者次第のところもある\n",
    "  \n",
    "**［以下のコードの処理内容］**\n",
    "* 1～2行目: ファイルをDataFrameとして読み込み，変数`df`に代入\n",
    "* 3～5行目: 列の削除，欠損値の対処，外れ値の削除\n",
    "* 6～13行目: 説明変数と目的変数に分割し，変数`x`と`t`にそれぞれ代入\n",
    "* 14～15行目:  説明変数と目的変数を訓練データ（70％）と検証データ（30％）に分割し，`x_train`, `x_test`, `t_train`, `t_test`にそれぞれ代入\n",
    "* 16～28行目: データの標準化を行い，その結果を`x_train_s`, `x_test_s`, `t_train_s`, `t_test_s`にそれぞれ代入\n",
    "* 29行目:  `sklearn` (scikit-learn) の`linear_model`モジュール内にある`LinearRegression`クラスを読み込む \n",
    "* 30行目: `LinearRegression()`で，モデルの学習を行うためのオブジェクトを`LinearRegression`クラスから生成し，変数`linear_regression_model`に代入\n",
    "* 31行目: 標準化した訓練データ（`x_train_s`と`t_train_s`）を用いて，`fit`メソッドでモデルの学習を実行\n",
    "* 32行目: `linear_regression_model.score(X = x_train_s, y = t_train_s)`で，標準化した訓練データに対する決定係数を計算して変数`score_train`に代入\n",
    "* 33行目: `linear_regression_model.score(X = x_test_s, y = t_test_s)`で，標準化したテストデータに対する決定係数を計算して変数`score_test`に代入\n",
    "* 34行目: `print`関数とf-stringを使って，訓練データに対する決定係数（`score_train`）とテストデータに対する決定係数（`score_test`）を小数点以下3桁まで表示\n",
    "* 35行目: `linear_regression_model`オブジェクトの`coef_`属性から回帰係数（定数項以外）を取り出し，変数`a`に代入\n",
    "* 36行目: `linear_regression_model`オブジェクトの`intercept_`属性から定数項を取り出し，変数`b`に代入\n",
    "* 37行目: `print`関数とf-stringを使って，回帰係数`a`を表示\n",
    "* 38行目: `print`関数とf-stringを使って，定数項`b`を表示（標準化しているので 0 になる）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練データの決定係数=0.852 / テストデータの決定係数=0.727\n",
      "回帰係数（定数項以外）: [[-1.08   2.033  1.784  2.269 -0.434 -2.455 -1.831  0.516  0.008]]\n",
      "定数項: [0.]\n"
     ]
    }
   ],
   "source": [
    "url = 'https://bit.ly/4hwOUgx'\n",
    "df = pd.read_csv(url)\n",
    "df = df.drop(['CRIME'], axis = 1)\n",
    "df = df.fillna(df.mean())\n",
    "df = df.drop([76], axis = 0)\n",
    "x_cols = ['RM', 'PTRATIO', 'LSTAT']\n",
    "t_col = ['PRICE']\n",
    "x = df[x_cols]\n",
    "t = df[t_col]\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "pf = PolynomialFeatures(degree = 2, include_bias = False)\n",
    "x = pf.fit_transform(x)\n",
    "x = pd.DataFrame(x, columns = pf.get_feature_names_out())\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, t_train, t_test = train_test_split(x, t, test_size = 0.3, random_state = random_seed)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_x = StandardScaler()\n",
    "sc_x.fit(x_train)\n",
    "x_train_s = sc_x.transform(x_train)\n",
    "x_train_s = pd.DataFrame(x_train_s, columns = x_train.columns)\n",
    "x_test_s = sc_x.transform(x_test)\n",
    "x_test_s = pd.DataFrame(x_test_s, columns = x_test.columns)\n",
    "sc_t = StandardScaler()\n",
    "sc_t.fit(t_train)\n",
    "t_train_s = sc_t.transform(t_train)\n",
    "t_train_s = pd.DataFrame(t_train_s, columns = t_train.columns)\n",
    "t_test_s = sc_t.transform(t_test)\n",
    "t_test_s = pd.DataFrame(t_test_s, columns = t_test.columns)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "linear_regression_model = LinearRegression()\n",
    "linear_regression_model.fit(X = x_train_s, y = t_train_s)\n",
    "score_train = linear_regression_model.score(X = x_train_s, y = t_train_s)\n",
    "score_test = linear_regression_model.score(X = x_test_s, y = t_test_s)\n",
    "print(f'訓練データの決定係数={score_train:.3f} / テストデータの決定係数={score_test:.3f}')\n",
    "a = linear_regression_model.coef_\n",
    "b = linear_regression_model.intercept_\n",
    "print(f'回帰係数（定数項以外）: {a}')\n",
    "print(f'定数項: {b}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8UoWNVxr8Gmp"
   },
   "source": [
    "# リッジ回帰モデルの学習と評価\n",
    "* 多項式回帰モデルの学習を行った結果，過学習が起きていることが確認できた\n",
    "* この問題を改善するためにモデルを変更する\n",
    "* ここでは，リッジ回帰モデルで学習を試みる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KLy6TOUsagXi"
   },
   "source": [
    "## モデルの学習と評価\n",
    "* ここでは，正則化パラメータを5としたときの，リッジ回帰モデルの学習を行う\n",
    "* リッジ回帰モデルの学習は，`sklearn`（scikit-learn）の`linear_model`モジュールにおける`Ridge`クラスを使う\n",
    "* `Ridge`クラスは，線形回帰モデルの学習を行うときに用いるクラス（`LinearRegression`クラス）とは異なるクラス\n",
    "* リッジ回帰モデルの学習の流れ:\n",
    ">* `Ridge`クラスを読み込む（インポートする）\n",
    ">* インポートの書式: `from sklearn.linear_model import Ridge`\n",
    ">* `Ridge`クラスのオブジェクトを生成し，変数に代入する\n",
    ">* オブジェクト生成の書式: `変数 = Ridge(alpha = 正則化パラメータ)`\n",
    ">* モデルを学習する\n",
    ">* モデルの学習の書式（これまでのモデルと同様）: `変数.fit(説明変数データ, 目的変数データ)`\n",
    "* 以下のコードで，モデルの学習と評価（訓練データとテストデータに対する決定係数をそれぞれ計算）を行う\n",
    "* 決定係数の計算は，これまでのモデルと同様に`score`メソッドを用いる\n",
    "* 実行結果の決定係数から，過学習の問題が改善されていることがわかる\n",
    "* ただし，正則化パラメータの値やデータによってモデルの性能（決定係数）が変わってくることに注意する\n",
    "  \n",
    "**［以下のコードの処理内容］**\n",
    "* 1～2行目: ファイルをDataFrameとして読み込み，変数`df`に代入\n",
    "* 3～5行目: 列の削除，欠損値の対処，外れ値の削除\n",
    "* 6～13行目: 説明変数と目的変数に分割し，変数`x`と`t`にそれぞれ代入\n",
    "* 14～15行目:  説明変数と目的変数を訓練データ（70％）と検証データ（30％）に分割し，`x_train`, `x_test`, `t_train`, `t_test`にそれぞれ代入\n",
    "* 16～28行目: データの標準化を行い，その結果を`x_train_s`, `x_test_s`, `t_train_s`, `t_test_s`にそれぞれ代入\n",
    "* 29行目:  `sklearn` (scikit-learn) の`linear_model`モジュール内にある`Ridge`クラスを読み込む \n",
    "* 30行目: `Ridge(alpha = 5)`で，モデルの学習を行うためのオブジェクトを`Ridge`クラスから生成し，変数`ridge_regression_model`に代入\n",
    ">* `alpha = 5`で，正則化パラメータを 5と設定\n",
    "* 31行目: 標準化した訓練データ（`x_train_s`と`t_train_s`）を用いて，`fit`メソッドでモデルの学習を実行\n",
    "* 32行目: `ridge_regression_model.score(X = x_train_s, y = t_train_s)`で，標準化した訓練データに対する決定係数を計算して変数`score_train`に代入\n",
    "* 33行目: `ridge_regression_model.score(X = x_test_s, y = t_test_s)`で，標準化したテストデータに対する決定係数を計算して変数`score_test`に代入\n",
    "* 34行目: `print`関数とf-stringを使って，訓練データに対する決定係数（`score_train`）とテストデータに対する決定係数（`score_test`）を小数点以下3桁まで表示\n",
    "* 35行目: `ridge_regression_model`オブジェクトの`coef_`属性から回帰係数（定数項以外）を取り出し，変数`a`に代入\n",
    "* 36行目: `ridge_regression_model`オブジェクトの`intercept_`属性から定数項を取り出し，変数`b`に代入\n",
    "* 37行目: `print`関数とf-stringを使って，回帰係数`a`を表示\n",
    "* 38行目: `print`関数とf-stringを使って，定数項`b`を表示（標準化しているので 0 になる）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 699,
     "status": "ok",
     "timestamp": 1716690078567,
     "user": {
      "displayName": "Takahiro YOSHIDA",
      "userId": "00096252480874798687"
     },
     "user_tz": -540
    },
    "id": "QzbmNaVZS-IR",
    "outputId": "7f3b3809-a748-4e4d-f7be-f21d1e808c19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練データの決定係数=0.756 / テストデータの決定係数=0.835\n",
      "回帰係数（定数項以外）: [ 0.123  0.016 -0.16   0.57  -0.275 -0.418  0.013 -0.023  0.278]\n",
      "定数項: [0.]\n"
     ]
    }
   ],
   "source": [
    "url = 'https://bit.ly/4hwOUgx'\n",
    "df = pd.read_csv(url)\n",
    "df = df.drop(['CRIME'], axis = 1)\n",
    "df = df.fillna(df.mean())\n",
    "df = df.drop([76], axis = 0)\n",
    "x_cols = ['RM', 'PTRATIO', 'LSTAT']\n",
    "t_col = ['PRICE']\n",
    "x = df[x_cols]\n",
    "t = df[t_col]\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "pf = PolynomialFeatures(degree = 2, include_bias = False)\n",
    "x = pf.fit_transform(x)\n",
    "x = pd.DataFrame(x, columns = pf.get_feature_names_out())\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, t_train, t_test = train_test_split(x, t, test_size = 0.3, random_state = random_seed)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_x = StandardScaler()\n",
    "sc_x.fit(x_train)\n",
    "x_train_s = sc_x.transform(x_train)\n",
    "x_train_s = pd.DataFrame(x_train_s, columns = x_train.columns)\n",
    "x_test_s = sc_x.transform(x_test)\n",
    "x_test_s = pd.DataFrame(x_test_s, columns = x_test.columns)\n",
    "sc_t = StandardScaler()\n",
    "sc_t.fit(t_train)\n",
    "t_train_s = sc_t.transform(t_train)\n",
    "t_train_s = pd.DataFrame(t_train_s, columns = t_train.columns)\n",
    "t_test_s = sc_t.transform(t_test)\n",
    "t_test_s = pd.DataFrame(t_test_s, columns = t_test.columns)\n",
    "from sklearn.linear_model import Ridge\n",
    "ridge_regression_model = Ridge(alpha = 5)\n",
    "ridge_regression_model.fit(X = x_train_s, y = t_train_s)\n",
    "score_train = ridge_regression_model.score(X = x_train_s, y = t_train_s)\n",
    "score_test = ridge_regression_model.score(X = x_test_s, y = t_test_s)\n",
    "print(f'訓練データの決定係数={score_train:.3f} / テストデータの決定係数={score_test:.3f}')\n",
    "a = ridge_regression_model.coef_\n",
    "b = ridge_regression_model.intercept_\n",
    "print(f'回帰係数（定数項以外）: {a}')\n",
    "print(f'定数項: {b}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 参考コード（理解する必要はない）\n",
    "* 以下のコードは，正則化パラメータを0.1から20.0まで0.1刻みで変化させたときの決定係数を求め，決定係数の最大値とそのときの正則化パラメータの値を出力する\n",
    "* また，データを分割する際に使用する乱数の種を変数`seed`で指定している（1行目）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23351,
     "status": "ok",
     "timestamp": 1716539627228,
     "user": {
      "displayName": "Takahiro YOSHIDA",
      "userId": "00096252480874798687"
     },
     "user_tz": -540
    },
    "id": "HzRhAGAnbAgw",
    "outputId": "2805e6d4-029f-4849-9c3b-0b3f1f4533eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最大の決定係数: 0.836\n",
      "そのときの正則化パラメータ: 3.7\n"
     ]
    }
   ],
   "source": [
    "seed = 1 # 乱数の種\n",
    "url = 'https://bit.ly/4hwOUgx'\n",
    "df = pd.read_csv(url)\n",
    "df = df.drop(['CRIME'], axis = 1)\n",
    "df = df.fillna(df.mean())\n",
    "df = df.drop([76], axis = 0)\n",
    "x_cols = ['RM', 'PTRATIO', 'LSTAT']\n",
    "t_col = ['PRICE']\n",
    "x = df[x_cols]\n",
    "t = df[t_col]\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "pf = PolynomialFeatures(degree = 2, include_bias = False)\n",
    "x = pf.fit_transform(x)\n",
    "x = pd.DataFrame(x, columns = pf.get_feature_names_out())\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, t_train, t_test = train_test_split(x, t, test_size = 0.3, random_state = seed)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_x = StandardScaler()\n",
    "sc_x.fit(x_train)\n",
    "x_train_s = sc_x.transform(x_train)\n",
    "x_train_s = pd.DataFrame(x_train_s, columns = x_train.columns)\n",
    "x_test_s = sc_x.transform(x_test)\n",
    "x_test_s = pd.DataFrame(x_test_s, columns = x_test.columns)\n",
    "sc_t = StandardScaler()\n",
    "sc_t.fit(t_train)\n",
    "t_train_s = sc_t.transform(t_train)\n",
    "t_train_s = pd.DataFrame(t_train_s, columns = t_train.columns)\n",
    "t_test_s = sc_t.transform(t_test)\n",
    "t_test_s = pd.DataFrame(t_test_s, columns = t_test.columns)\n",
    "from sklearn.linear_model import Ridge\n",
    "max_score = 0 # 最大の決定係数を格納する変数\n",
    "max_param = 0 # そのときの正則化パラメータを格納する変数\n",
    "for i in range(1, 201):\n",
    "    param = i/10\n",
    "    ridge_regression_model = Ridge(alpha = param)\n",
    "    ridge_regression_model.fit(X = x_train_s, y = t_train_s)\n",
    "    score = ridge_regression_model.score(X = x_test_s, y = t_test_s)\n",
    "    if score > max_score:\n",
    "        max_score = score\n",
    "        max_param = param\n",
    "print(f'最大の決定係数: {max_score:.3f}')\n",
    "print(f'そのときの正則化パラメータ: {max_param}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XrnAElGXai7g"
   },
   "source": [
    "## 回帰係数の大きさの比較\n",
    "* 次に，多項式回帰モデルとリッジ回帰モデルの大きさを比較する\n",
    "* 回帰係数（切片以外）は`coef_`プロパティ，切片は`intercept_`プロパティで確認できる\n",
    "* 以下のコードでは，多項式回帰モデルとリッジ回帰モデル（正則化パラメータは5）の学習をそれぞれ行い，回帰係数の絶対値の合計をそれぞれ計算している\n",
    "* なお，データの標準化により，定数項は 0 となるので，合計の計算には定数項を入れていない\n",
    "  \n",
    "**［以下のコードの処理内容］**\n",
    "* 1～2行目: ファイルをDataFrameとして読み込み，変数`df`に代入\n",
    "* 3～5行目: 列の削除，欠損値の対処，外れ値の削除\n",
    "* 6～13行目: 説明変数と目的変数に分割し，変数`x`と`t`にそれぞれ代入\n",
    "* 14～15行目:  説明変数と目的変数を訓練データ（70％）と検証データ（30％）に分割し，`x_train`, `x_test`, `t_train`, `t_test`にそれぞれ代入\n",
    "* 16～28行目: データの標準化を行い，その結果を`x_train_s`, `x_test_s`, `t_train_s`, `t_test_s`にそれぞれ代入\n",
    "* 29～33行目: 多項式回帰モデルの学習を行い，回帰係数を表示\n",
    "* 34～38行目: リッジ回帰モデルの学習を行い，回帰係数を表示\n",
    "* 39行目: `sum`関数と`abs`関数を使って，多項式回帰モデルの回帰係数の絶対値の合計を計算し，変数`sum_coef_linear`に代入\n",
    ">*  `abs`関数は引数でしていした数値の絶対値を返す\n",
    ">*  `coef_[0]`で，回帰係数のリストを取り出している\n",
    ">*  `sum`関数は引数で指定した複数の数値の合計を返す\n",
    "* 40行目: 同様に `sum`関数と`abs`関数を使って，リッジ回帰モデルの回帰係数の絶対値の合計を計算し，変数`sum_coef_ridge`に代入\n",
    ">*  `coef_`のデータ構造が，`linear_regression_model`と異なるので，回帰係数の指定が`coef_[0]`ではなく，`coef_`となっている\n",
    "* 41行目: `print`関数とf-stringを使って，多項式回帰モデルの回帰係数の絶対値の合計 `sum_coef_linear`を表示\n",
    "* 42行目: `print`関数とf-stringを使って，リッジ回帰モデルの回帰係数の絶対値の合計 `sum_coef_ridge`を表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mwucn6H6anaI",
    "outputId": "15b12020-b6f3-4161-d192-18d5ee94e1e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "多項式回帰モデルの回帰係数（定数項以外）: [[-1.08   2.033  1.784  2.269 -0.434 -2.455 -1.831  0.516  0.008]]\n",
      "リッジ回帰モデルの回帰係数（定数項以外）: [ 0.123  0.016 -0.16   0.57  -0.275 -0.418  0.013 -0.023  0.278]\n",
      "多項式回帰モデルの回帰係数の合計: 12.411\n",
      "リッジ回帰モデルの回帰係数の合計: 1.876\n"
     ]
    }
   ],
   "source": [
    "url = 'https://bit.ly/4hwOUgx'\n",
    "df = pd.read_csv(url)\n",
    "df = df.drop(['CRIME'], axis = 1)\n",
    "df = df.fillna(df.mean())\n",
    "df = df.drop([76], axis = 0)\n",
    "x_cols = ['RM', 'PTRATIO', 'LSTAT']\n",
    "t_col = ['PRICE']\n",
    "x = df[x_cols]\n",
    "t = df[t_col]\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "pf = PolynomialFeatures(degree = 2, include_bias = False)\n",
    "x = pf.fit_transform(x)\n",
    "x = pd.DataFrame(x, columns = pf.get_feature_names_out())\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, t_train, t_test = train_test_split(x, t, test_size = 0.3, random_state = random_seed)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_x = StandardScaler()\n",
    "sc_x.fit(x_train)\n",
    "x_train_s = sc_x.transform(x_train)\n",
    "x_train_s = pd.DataFrame(x_train_s, columns = x_train.columns)\n",
    "x_test_s = sc_x.transform(x_test)\n",
    "x_test_s = pd.DataFrame(x_test_s, columns = x_test.columns)\n",
    "sc_t = StandardScaler()\n",
    "sc_t.fit(t_train)\n",
    "t_train_s = sc_t.transform(t_train)\n",
    "t_train_s = pd.DataFrame(t_train_s, columns = t_train.columns)\n",
    "t_test_s = sc_t.transform(t_test)\n",
    "t_test_s = pd.DataFrame(t_test_s, columns = t_test.columns)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "linear_regression_model = LinearRegression()\n",
    "linear_regression_model.fit(X = x_train_s, y = t_train_s)\n",
    "a = linear_regression_model.coef_\n",
    "print(f'多項式回帰モデルの回帰係数（定数項以外）: {a}')\n",
    "from sklearn.linear_model import Ridge\n",
    "ridge_regression_model = Ridge(alpha = 5)\n",
    "ridge_regression_model.fit(X = x_train_s, y = t_train_s)\n",
    "a = ridge_regression_model.coef_\n",
    "print(f'リッジ回帰モデルの回帰係数（定数項以外）: {a}')\n",
    "sum_coef_linear = sum(abs(linear_regression_model.coef_[0]))\n",
    "sum_coef_ridge = sum(abs(ridge_regression_model.coef_))\n",
    "print(f'多項式回帰モデルの回帰係数の合計: {sum_coef_linear:.3f}')\n",
    "print(f'リッジ回帰モデルの回帰係数の合計: {sum_coef_ridge:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BcATIxVuaVvU"
   },
   "source": [
    "# ラッソ回帰モデルの学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルの学習と評価\n",
    "* ここでは，正則化パラメータを0.05としたときの，ラッソ回帰モデルの学習を行う\n",
    "* ラッソ回帰モデルの学習は，`sklearn`（scikit-learn）の`linear_model`モジュールにおける`Lasso`クラスを使う\n",
    "* 学習の流れは，リッジ回帰モデルと同様\n",
    "* ラッソ回帰モデルの学習の流れ:\n",
    ">* `Lasso`クラスを読み込む（インポートする）\n",
    ">* インポートの書式: `from sklearn.linear_model import Lasso`\n",
    ">* `Lasso`クラスのオブジェクトを生成し，変数に代入する\n",
    ">* オブジェクト生成の書式: `変数 = Lasso(alpha = 正則化パラメータ)`\n",
    ">* モデルを学習する\n",
    ">* モデルの学習の書式（これまでのモデルと同様）: `変数.fit(説明変数データ, 目的変数データ)`\n",
    "* 以下のコードで，モデルの学習と評価（訓練データとテストデータに対する決定係数をそれぞれ計算）を行う\n",
    "* 決定係数の計算は，これまでのモデルと同様に`score`メソッドを用いる\n",
    "* リッジ回帰モデルの学習と同様，正則化パラメータの値やデータによってモデルの性能（決定係数）が変わってくることに注意する\n",
    "* ラッソ回帰モデルの学習では，目的変数に影響を与えない説明変数の係数を0にするという特徴があるが，実行結果から．それが確認できる\n",
    "  \n",
    "**［以下のコードの処理内容］**\n",
    "* 1～2行目: ファイルをDataFrameとして読み込み，変数`df`に代入\n",
    "* 3～5行目: 列の削除，欠損値の対処，外れ値の削除\n",
    "* 6～13行目: 説明変数と目的変数に分割し，変数`x`と`t`にそれぞれ代入\n",
    "* 14～15行目:  説明変数と目的変数を訓練データ（70％）と検証データ（30％）に分割し，`x_train`, `x_test`, `t_train`, `t_test`にそれぞれ代入\n",
    "* 16～28行目: データの標準化を行い，その結果を`x_train_s`, `x_test_s`, `t_train_s`, `t_test_s`にそれぞれ代入\n",
    "* 29行目:  `sklearn` (scikit-learn) の`linear_model`モジュール内にある`Lasso`クラスを読み込む \n",
    "* 30行目: `Lasso(alpha = 0.05)`で，モデルの学習を行うためのオブジェクトを`Lasso`クラスから生成し，変数`lasso_regression_model`に代入\n",
    ">* `alpha = 0.05`で，正則化パラメータを 0.05 と設定\n",
    "* 31行目: 標準化した訓練データ（`x_train_s`と`t_train_s`）を用いて，`fit`メソッドでモデルの学習を実行\n",
    "* 32行目: `lasso_regression_model.score(X = x_train_s, y = t_train_s)`で，標準化した訓練データに対する決定係数を計算して変数`score_train`に代入\n",
    "* 33行目: `lasso_regression_model.score(X = x_test_s, y = t_test_s)`で，標準化したテストデータに対する決定係数を計算して変数`score_test`に代入\n",
    "* 34行目: `print`関数とf-stringを使って，訓練データに対する決定係数（`score_train`）とテストデータに対する決定係数（`score_test`）を小数点以下3桁まで表示\n",
    "* 35行目: `lasso_regression_model`オブジェクトの`coef_`属性から回帰係数（定数項以外）を取り出し，変数`a`に代入\n",
    "* 36行目: `a`をDataFrameに変換し，インデックスと列名を加え見やすくしたものを`display`関数で表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "_jj7iiNpaZde",
    "outputId": "81f22ff2-aa53-4e86-d3c9-e8799e83f998"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練データの決定係数=0.731 / テストデータの決定係数=0.836\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>係数</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RM</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PTRATIO</th>\n",
       "      <td>-0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTAT</th>\n",
       "      <td>-0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RM^2</th>\n",
       "      <td>0.668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RM PTRATIO</th>\n",
       "      <td>-0.218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RM LSTAT</th>\n",
       "      <td>-0.310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PTRATIO^2</th>\n",
       "      <td>-0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PTRATIO LSTAT</th>\n",
       "      <td>-0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTAT^2</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  係数\n",
       "RM             0.000\n",
       "PTRATIO       -0.000\n",
       "LSTAT         -0.000\n",
       "RM^2           0.668\n",
       "RM PTRATIO    -0.218\n",
       "RM LSTAT      -0.310\n",
       "PTRATIO^2     -0.000\n",
       "PTRATIO LSTAT -0.000\n",
       "LSTAT^2        0.000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "url = 'https://bit.ly/4hwOUgx'\n",
    "df = pd.read_csv(url)\n",
    "df = df.drop(['CRIME'], axis = 1)\n",
    "df = df.fillna(df.mean())\n",
    "df = df.drop([76], axis = 0)\n",
    "x_cols = ['RM', 'PTRATIO', 'LSTAT']\n",
    "t_col = ['PRICE']\n",
    "x = df[x_cols]\n",
    "t = df[t_col]\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "pf = PolynomialFeatures(degree = 2, include_bias = False)\n",
    "x = pf.fit_transform(x)\n",
    "x = pd.DataFrame(x, columns = pf.get_feature_names_out())\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, t_train, t_test = train_test_split(x, t, test_size = 0.3, random_state = random_seed)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_x = StandardScaler()\n",
    "sc_x.fit(x_train)\n",
    "x_train_s = sc_x.transform(x_train)\n",
    "x_train_s = pd.DataFrame(x_train_s, columns = x_train.columns)\n",
    "x_test_s = sc_x.transform(x_test)\n",
    "x_test_s = pd.DataFrame(x_test_s, columns = x_test.columns)\n",
    "sc_t = StandardScaler()\n",
    "sc_t.fit(t_train)\n",
    "t_train_s = sc_t.transform(t_train)\n",
    "t_train_s = pd.DataFrame(t_train_s, columns = t_train.columns)\n",
    "t_test_s = sc_t.transform(t_test)\n",
    "t_test_s = pd.DataFrame(t_test_s, columns = t_test.columns)\n",
    "from sklearn.linear_model import Lasso\n",
    "lasso_regression_model = Lasso(alpha = 0.05)\n",
    "lasso_regression_model.fit(X = x_train_s, y = t_train_s)\n",
    "score_train = lasso_regression_model.score(X = x_train_s, y = t_train_s)\n",
    "score_test = lasso_regression_model.score(X = x_test_s, y = t_test_s)\n",
    "print(f'訓練データの決定係数={score_train:.3f} / テストデータの決定係数={score_test:.3f}')\n",
    "a = lasso_regression_model.coef_\n",
    "display(pd.DataFrame(a, index = pf.get_feature_names_out(), columns = ['係数']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3bAbydDUc-E_"
   },
   "source": [
    "# 回帰木モデルの学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの前処理\n",
    "* ここでは，回帰木モデルの学習を行う\n",
    "* 説明変数は，目的変数である`PRICE`を除くすべての特徴量とする\n",
    "* また，回帰木モデルは，データのスケールや外れ値の影響を受けない（受けにくい）ので，データの標準化と外れ値の対処は行わず学習する\n",
    "* この特徴は分類木モデルも同様\n",
    "\n",
    "  \n",
    "**［以下のコードの処理内容］**\n",
    "* 1～2行目: ファイルをDataFrameとして読み込み，変数`df`に代入\n",
    "* 3～4行目: 列の削除，欠損値の対処\n",
    "* 5～7行目: 説明変数と目的変数に分割し，変数`x`と`t`にそれぞれ代入\n",
    ">* `df.drop(['PRICE'], axis = 1)`で，`PRICE`列を削除したDataFrame（これが説明変数となる）を変数`x`に代入している\n",
    "* 8～9行目: 説明変数と目的変数を訓練データ（70％）と検証データ（30％）に分割し，`x_train`, `x_test`, `t_train`, `t_test`にそれぞれ代入\n",
    "* 10～17行目: `x_train`, `x_test`, `t_train`, `t_test`をそれぞれ表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ x_train ================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.000</td>\n",
       "      <td>5.190</td>\n",
       "      <td>0</td>\n",
       "      <td>0.515</td>\n",
       "      <td>6.310</td>\n",
       "      <td>38.500</td>\n",
       "      <td>6.458</td>\n",
       "      <td>5.000</td>\n",
       "      <td>224</td>\n",
       "      <td>20.200</td>\n",
       "      <td>6.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.000</td>\n",
       "      <td>18.100</td>\n",
       "      <td>0</td>\n",
       "      <td>0.693</td>\n",
       "      <td>5.453</td>\n",
       "      <td>100.000</td>\n",
       "      <td>1.490</td>\n",
       "      <td>24.000</td>\n",
       "      <td>666</td>\n",
       "      <td>20.200</td>\n",
       "      <td>30.590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.000</td>\n",
       "      <td>9.900</td>\n",
       "      <td>0</td>\n",
       "      <td>0.544</td>\n",
       "      <td>6.382</td>\n",
       "      <td>67.200</td>\n",
       "      <td>3.533</td>\n",
       "      <td>4.000</td>\n",
       "      <td>304</td>\n",
       "      <td>18.400</td>\n",
       "      <td>10.360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.000</td>\n",
       "      <td>18.100</td>\n",
       "      <td>0</td>\n",
       "      <td>0.740</td>\n",
       "      <td>6.219</td>\n",
       "      <td>100.000</td>\n",
       "      <td>2.005</td>\n",
       "      <td>24.000</td>\n",
       "      <td>666</td>\n",
       "      <td>20.200</td>\n",
       "      <td>16.590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.000</td>\n",
       "      <td>18.100</td>\n",
       "      <td>0</td>\n",
       "      <td>0.659</td>\n",
       "      <td>4.138</td>\n",
       "      <td>100.000</td>\n",
       "      <td>1.178</td>\n",
       "      <td>24.000</td>\n",
       "      <td>666</td>\n",
       "      <td>20.200</td>\n",
       "      <td>23.340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.000</td>\n",
       "      <td>3.240</td>\n",
       "      <td>0</td>\n",
       "      <td>0.460</td>\n",
       "      <td>6.333</td>\n",
       "      <td>17.200</td>\n",
       "      <td>5.215</td>\n",
       "      <td>4.000</td>\n",
       "      <td>430</td>\n",
       "      <td>16.900</td>\n",
       "      <td>7.340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000</td>\n",
       "      <td>18.100</td>\n",
       "      <td>0</td>\n",
       "      <td>0.583</td>\n",
       "      <td>5.905</td>\n",
       "      <td>53.200</td>\n",
       "      <td>3.152</td>\n",
       "      <td>24.000</td>\n",
       "      <td>666</td>\n",
       "      <td>20.200</td>\n",
       "      <td>11.450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.000</td>\n",
       "      <td>11.930</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.700</td>\n",
       "      <td>2.288</td>\n",
       "      <td>1.000</td>\n",
       "      <td>273</td>\n",
       "      <td>21.000</td>\n",
       "      <td>9.080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12.500</td>\n",
       "      <td>7.870</td>\n",
       "      <td>0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.009</td>\n",
       "      <td>82.900</td>\n",
       "      <td>6.227</td>\n",
       "      <td>5.000</td>\n",
       "      <td>311</td>\n",
       "      <td>15.200</td>\n",
       "      <td>13.270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.000</td>\n",
       "      <td>2.460</td>\n",
       "      <td>0</td>\n",
       "      <td>0.488</td>\n",
       "      <td>6.153</td>\n",
       "      <td>68.800</td>\n",
       "      <td>3.280</td>\n",
       "      <td>3.000</td>\n",
       "      <td>193</td>\n",
       "      <td>17.800</td>\n",
       "      <td>13.150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ZN  INDUS  CHAS   NOX    RM     AGE   DIS    RAD  TAX  PTRATIO  LSTAT\n",
       "67  0.000  5.190     0 0.515 6.310  38.500 6.458  5.000  224   20.200  6.750\n",
       "99  0.000 18.100     0 0.693 5.453 100.000 1.490 24.000  666   20.200 30.590\n",
       "54  0.000  9.900     0 0.544 6.382  67.200 3.533  4.000  304   18.400 10.360\n",
       "95  0.000 18.100     0 0.740 6.219 100.000 2.005 24.000  666   20.200 16.590\n",
       "88  0.000 18.100     0 0.659 4.138 100.000 1.178 24.000  666   20.200 23.340\n",
       "..    ...    ...   ...   ...   ...     ...   ...    ...  ...      ...    ...\n",
       "75  0.000  3.240     0 0.460 6.333  17.200 5.215  4.000  430   16.900  7.340\n",
       "9   0.000 18.100     0 0.583 5.905  53.200 3.152 24.000  666   20.200 11.450\n",
       "72  0.000 11.930     0 0.573 6.120  76.700 2.288  1.000  273   21.000  9.080\n",
       "12 12.500  7.870     0 0.524 6.009  82.900 6.227  5.000  311   15.200 13.270\n",
       "37  0.000  2.460     0 0.488 6.153  68.800 3.280  3.000  193   17.800 13.150\n",
       "\n",
       "[70 rows x 11 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ t_train ================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>20.700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>23.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>18.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>11.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>22.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>20.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>18.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>29.600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    PRICE\n",
       "67 20.700\n",
       "99  5.000\n",
       "54 23.100\n",
       "95 18.400\n",
       "88 11.900\n",
       "..    ...\n",
       "75 22.600\n",
       "9  20.600\n",
       "72 20.600\n",
       "12 18.900\n",
       "37 29.600\n",
       "\n",
       "[70 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ x_test ================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>52.500</td>\n",
       "      <td>5.320</td>\n",
       "      <td>0</td>\n",
       "      <td>0.405</td>\n",
       "      <td>6.209</td>\n",
       "      <td>31.300</td>\n",
       "      <td>7.317</td>\n",
       "      <td>6.000</td>\n",
       "      <td>293</td>\n",
       "      <td>16.600</td>\n",
       "      <td>7.140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.000</td>\n",
       "      <td>18.100</td>\n",
       "      <td>0</td>\n",
       "      <td>0.532</td>\n",
       "      <td>6.242</td>\n",
       "      <td>64.700</td>\n",
       "      <td>3.424</td>\n",
       "      <td>24.000</td>\n",
       "      <td>666</td>\n",
       "      <td>20.200</td>\n",
       "      <td>10.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.000</td>\n",
       "      <td>18.100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.718</td>\n",
       "      <td>6.545</td>\n",
       "      <td>82.900</td>\n",
       "      <td>1.905</td>\n",
       "      <td>24.000</td>\n",
       "      <td>666</td>\n",
       "      <td>20.200</td>\n",
       "      <td>5.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.000</td>\n",
       "      <td>18.100</td>\n",
       "      <td>0</td>\n",
       "      <td>0.655</td>\n",
       "      <td>6.209</td>\n",
       "      <td>65.400</td>\n",
       "      <td>2.963</td>\n",
       "      <td>24.000</td>\n",
       "      <td>666</td>\n",
       "      <td>20.200</td>\n",
       "      <td>13.220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.000</td>\n",
       "      <td>19.580</td>\n",
       "      <td>0</td>\n",
       "      <td>0.871</td>\n",
       "      <td>5.186</td>\n",
       "      <td>93.800</td>\n",
       "      <td>1.530</td>\n",
       "      <td>5.000</td>\n",
       "      <td>403</td>\n",
       "      <td>14.700</td>\n",
       "      <td>28.320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.000</td>\n",
       "      <td>6.200</td>\n",
       "      <td>0</td>\n",
       "      <td>0.504</td>\n",
       "      <td>7.163</td>\n",
       "      <td>79.900</td>\n",
       "      <td>3.216</td>\n",
       "      <td>8.000</td>\n",
       "      <td>307</td>\n",
       "      <td>17.400</td>\n",
       "      <td>6.360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.000</td>\n",
       "      <td>8.560</td>\n",
       "      <td>0</td>\n",
       "      <td>0.520</td>\n",
       "      <td>5.851</td>\n",
       "      <td>96.700</td>\n",
       "      <td>2.107</td>\n",
       "      <td>5.000</td>\n",
       "      <td>384</td>\n",
       "      <td>20.900</td>\n",
       "      <td>16.470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>25.000</td>\n",
       "      <td>4.860</td>\n",
       "      <td>0</td>\n",
       "      <td>0.426</td>\n",
       "      <td>6.302</td>\n",
       "      <td>32.200</td>\n",
       "      <td>5.401</td>\n",
       "      <td>4.000</td>\n",
       "      <td>281</td>\n",
       "      <td>19.000</td>\n",
       "      <td>6.720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.000</td>\n",
       "      <td>19.580</td>\n",
       "      <td>0</td>\n",
       "      <td>0.605</td>\n",
       "      <td>5.875</td>\n",
       "      <td>94.600</td>\n",
       "      <td>2.426</td>\n",
       "      <td>5.000</td>\n",
       "      <td>403</td>\n",
       "      <td>14.700</td>\n",
       "      <td>14.430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.000</td>\n",
       "      <td>18.100</td>\n",
       "      <td>0</td>\n",
       "      <td>0.584</td>\n",
       "      <td>5.427</td>\n",
       "      <td>95.400</td>\n",
       "      <td>2.430</td>\n",
       "      <td>24.000</td>\n",
       "      <td>666</td>\n",
       "      <td>20.200</td>\n",
       "      <td>18.140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.000</td>\n",
       "      <td>6.200</td>\n",
       "      <td>0</td>\n",
       "      <td>0.507</td>\n",
       "      <td>8.247</td>\n",
       "      <td>70.400</td>\n",
       "      <td>3.652</td>\n",
       "      <td>8.000</td>\n",
       "      <td>307</td>\n",
       "      <td>17.400</td>\n",
       "      <td>3.950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.000</td>\n",
       "      <td>6.910</td>\n",
       "      <td>0</td>\n",
       "      <td>0.448</td>\n",
       "      <td>5.602</td>\n",
       "      <td>62.000</td>\n",
       "      <td>6.088</td>\n",
       "      <td>3.000</td>\n",
       "      <td>233</td>\n",
       "      <td>17.900</td>\n",
       "      <td>16.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.000</td>\n",
       "      <td>18.100</td>\n",
       "      <td>0</td>\n",
       "      <td>0.693</td>\n",
       "      <td>6.404</td>\n",
       "      <td>100.000</td>\n",
       "      <td>1.639</td>\n",
       "      <td>24.000</td>\n",
       "      <td>666</td>\n",
       "      <td>20.200</td>\n",
       "      <td>20.310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.000</td>\n",
       "      <td>4.050</td>\n",
       "      <td>0</td>\n",
       "      <td>0.510</td>\n",
       "      <td>6.416</td>\n",
       "      <td>84.100</td>\n",
       "      <td>2.646</td>\n",
       "      <td>5.000</td>\n",
       "      <td>296</td>\n",
       "      <td>16.600</td>\n",
       "      <td>9.040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.000</td>\n",
       "      <td>8.140</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.965</td>\n",
       "      <td>89.200</td>\n",
       "      <td>4.012</td>\n",
       "      <td>4.000</td>\n",
       "      <td>307</td>\n",
       "      <td>21.000</td>\n",
       "      <td>13.830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.000</td>\n",
       "      <td>4.050</td>\n",
       "      <td>0</td>\n",
       "      <td>0.510</td>\n",
       "      <td>6.546</td>\n",
       "      <td>33.100</td>\n",
       "      <td>3.132</td>\n",
       "      <td>5.000</td>\n",
       "      <td>296</td>\n",
       "      <td>16.600</td>\n",
       "      <td>5.330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>12.500</td>\n",
       "      <td>6.070</td>\n",
       "      <td>0</td>\n",
       "      <td>0.409</td>\n",
       "      <td>5.594</td>\n",
       "      <td>36.800</td>\n",
       "      <td>6.498</td>\n",
       "      <td>4.000</td>\n",
       "      <td>345</td>\n",
       "      <td>18.900</td>\n",
       "      <td>13.090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.000</td>\n",
       "      <td>5.960</td>\n",
       "      <td>0</td>\n",
       "      <td>0.499</td>\n",
       "      <td>5.850</td>\n",
       "      <td>41.500</td>\n",
       "      <td>3.934</td>\n",
       "      <td>5.000</td>\n",
       "      <td>279</td>\n",
       "      <td>19.200</td>\n",
       "      <td>8.770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.000</td>\n",
       "      <td>5.960</td>\n",
       "      <td>0</td>\n",
       "      <td>0.499</td>\n",
       "      <td>5.841</td>\n",
       "      <td>61.400</td>\n",
       "      <td>3.378</td>\n",
       "      <td>5.000</td>\n",
       "      <td>279</td>\n",
       "      <td>19.200</td>\n",
       "      <td>11.410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000</td>\n",
       "      <td>5.960</td>\n",
       "      <td>0</td>\n",
       "      <td>0.499</td>\n",
       "      <td>5.966</td>\n",
       "      <td>30.200</td>\n",
       "      <td>3.847</td>\n",
       "      <td>5.000</td>\n",
       "      <td>279</td>\n",
       "      <td>19.200</td>\n",
       "      <td>10.130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82.500</td>\n",
       "      <td>2.030</td>\n",
       "      <td>0</td>\n",
       "      <td>0.415</td>\n",
       "      <td>6.162</td>\n",
       "      <td>38.400</td>\n",
       "      <td>6.270</td>\n",
       "      <td>2.000</td>\n",
       "      <td>348</td>\n",
       "      <td>14.700</td>\n",
       "      <td>7.430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>55.000</td>\n",
       "      <td>3.780</td>\n",
       "      <td>0</td>\n",
       "      <td>0.484</td>\n",
       "      <td>6.874</td>\n",
       "      <td>28.100</td>\n",
       "      <td>6.465</td>\n",
       "      <td>5.000</td>\n",
       "      <td>370</td>\n",
       "      <td>17.600</td>\n",
       "      <td>4.610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.000</td>\n",
       "      <td>18.100</td>\n",
       "      <td>0</td>\n",
       "      <td>0.671</td>\n",
       "      <td>6.380</td>\n",
       "      <td>96.200</td>\n",
       "      <td>1.386</td>\n",
       "      <td>24.000</td>\n",
       "      <td>666</td>\n",
       "      <td>20.200</td>\n",
       "      <td>23.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>22.000</td>\n",
       "      <td>5.860</td>\n",
       "      <td>0</td>\n",
       "      <td>0.431</td>\n",
       "      <td>6.957</td>\n",
       "      <td>6.800</td>\n",
       "      <td>8.907</td>\n",
       "      <td>7.000</td>\n",
       "      <td>330</td>\n",
       "      <td>19.100</td>\n",
       "      <td>3.530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.000</td>\n",
       "      <td>8.140</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.072</td>\n",
       "      <td>100.000</td>\n",
       "      <td>4.175</td>\n",
       "      <td>4.000</td>\n",
       "      <td>307</td>\n",
       "      <td>21.000</td>\n",
       "      <td>13.040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.000</td>\n",
       "      <td>2.460</td>\n",
       "      <td>0</td>\n",
       "      <td>0.488</td>\n",
       "      <td>7.765</td>\n",
       "      <td>83.300</td>\n",
       "      <td>2.741</td>\n",
       "      <td>3.000</td>\n",
       "      <td>193</td>\n",
       "      <td>17.800</td>\n",
       "      <td>7.560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.000</td>\n",
       "      <td>4.490</td>\n",
       "      <td>0</td>\n",
       "      <td>0.449</td>\n",
       "      <td>6.389</td>\n",
       "      <td>48.000</td>\n",
       "      <td>4.779</td>\n",
       "      <td>3.000</td>\n",
       "      <td>247</td>\n",
       "      <td>18.500</td>\n",
       "      <td>9.620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>20.000</td>\n",
       "      <td>6.960</td>\n",
       "      <td>0</td>\n",
       "      <td>0.464</td>\n",
       "      <td>6.538</td>\n",
       "      <td>58.700</td>\n",
       "      <td>3.917</td>\n",
       "      <td>3.000</td>\n",
       "      <td>223</td>\n",
       "      <td>18.600</td>\n",
       "      <td>7.730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.000</td>\n",
       "      <td>25.650</td>\n",
       "      <td>0</td>\n",
       "      <td>0.581</td>\n",
       "      <td>5.613</td>\n",
       "      <td>95.600</td>\n",
       "      <td>1.757</td>\n",
       "      <td>2.000</td>\n",
       "      <td>188</td>\n",
       "      <td>19.100</td>\n",
       "      <td>27.260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>80.000</td>\n",
       "      <td>4.950</td>\n",
       "      <td>0</td>\n",
       "      <td>0.411</td>\n",
       "      <td>6.630</td>\n",
       "      <td>23.400</td>\n",
       "      <td>5.117</td>\n",
       "      <td>4.000</td>\n",
       "      <td>245</td>\n",
       "      <td>19.200</td>\n",
       "      <td>4.700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ZN  INDUS  CHAS   NOX    RM     AGE   DIS    RAD  TAX  PTRATIO  LSTAT\n",
       "80 52.500  5.320     0 0.405 6.209  31.300 7.317  6.000  293   16.600  7.140\n",
       "84  0.000 18.100     0 0.532 6.242  64.700 3.424 24.000  666   20.200 10.740\n",
       "33  0.000 18.100     1 0.718 6.545  82.900 1.905 24.000  666   20.200  5.290\n",
       "81  0.000 18.100     0 0.655 6.209  65.400 2.963 24.000  666   20.200 13.220\n",
       "93  0.000 19.580     0 0.871 5.186  93.800 1.530  5.000  403   14.700 28.320\n",
       "17  0.000  6.200     0 0.504 7.163  79.900 3.216  8.000  307   17.400  6.360\n",
       "36  0.000  8.560     0 0.520 5.851  96.700 2.107  5.000  384   20.900 16.470\n",
       "82 25.000  4.860     0 0.426 6.302  32.200 5.401  4.000  281   19.000  6.720\n",
       "69  0.000 19.580     0 0.605 5.875  94.600 2.426  5.000  403   14.700 14.430\n",
       "65  0.000 18.100     0 0.584 5.427  95.400 2.430 24.000  666   20.200 18.140\n",
       "92  0.000  6.200     0 0.507 8.247  70.400 3.652  8.000  307   17.400  3.950\n",
       "39  0.000  6.910     0 0.448 5.602  62.000 6.088  3.000  233   17.900 16.200\n",
       "56  0.000 18.100     0 0.693 6.404 100.000 1.639 24.000  666   20.200 20.310\n",
       "52  0.000  4.050     0 0.510 6.416  84.100 2.646  5.000  296   16.600  9.040\n",
       "51  0.000  8.140     0 0.538 5.965  89.200 4.012  4.000  307   21.000 13.830\n",
       "32  0.000  4.050     0 0.510 6.546  33.100 3.132  5.000  296   16.600  5.330\n",
       "31 12.500  6.070     0 0.409 5.594  36.800 6.498  4.000  345   18.900 13.090\n",
       "44  0.000  5.960     0 0.499 5.850  41.500 3.934  5.000  279   19.200  8.770\n",
       "78  0.000  5.960     0 0.499 5.841  61.400 3.378  5.000  279   19.200 11.410\n",
       "10  0.000  5.960     0 0.499 5.966  30.200 3.847  5.000  279   19.200 10.130\n",
       "2  82.500  2.030     0 0.415 6.162  38.400 6.270  2.000  348   14.700  7.430\n",
       "73 55.000  3.780     0 0.484 6.874  28.100 6.465  5.000  370   17.600  4.610\n",
       "97  0.000 18.100     0 0.671 6.380  96.200 1.386 24.000  666   20.200 23.690\n",
       "62 22.000  5.860     0 0.431 6.957   6.800 8.907  7.000  330   19.100  3.530\n",
       "19  0.000  8.140     0 0.538 6.072 100.000 4.175  4.000  307   21.000 13.040\n",
       "35  0.000  2.460     0 0.488 7.765  83.300 2.741  3.000  193   17.800  7.560\n",
       "94  0.000  4.490     0 0.449 6.389  48.000 4.779  3.000  247   18.500  9.620\n",
       "27 20.000  6.960     0 0.464 6.538  58.700 3.917  3.000  223   18.600  7.730\n",
       "46  0.000 25.650     0 0.581 5.613  95.600 1.757  2.000  188   19.100 27.260\n",
       "38 80.000  4.950     0 0.411 6.630  23.400 5.117  4.000  245   19.200  4.700"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ t_test ================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>23.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>23.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>21.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>21.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>17.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>31.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>19.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>24.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>17.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>13.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>48.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>19.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>12.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>23.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>19.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>29.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>17.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>21.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>20.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>24.700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>31.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>13.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>29.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>14.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>39.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>23.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>24.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>15.700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>27.900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PRICE\n",
       "80 23.200\n",
       "84 23.000\n",
       "33 21.900\n",
       "81 21.400\n",
       "93 17.800\n",
       "17 31.600\n",
       "36 19.500\n",
       "82 24.800\n",
       "69 17.400\n",
       "65 13.800\n",
       "92 48.300\n",
       "39 19.400\n",
       "56 12.100\n",
       "52 23.600\n",
       "51 19.600\n",
       "32 29.400\n",
       "31 17.400\n",
       "44 21.000\n",
       "78 20.000\n",
       "10 24.700\n",
       "2  24.100\n",
       "73 31.200\n",
       "97 13.100\n",
       "62 29.600\n",
       "19 14.500\n",
       "35 39.800\n",
       "94 23.900\n",
       "27 24.400\n",
       "46 15.700\n",
       "38 27.900"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "url = 'https://bit.ly/4hwOUgx'\n",
    "df = pd.read_csv(url)\n",
    "df = df.drop(['CRIME'], axis = 1)\n",
    "df = df.fillna(df.mean())\n",
    "t_col = ['PRICE']\n",
    "x = df.drop(['PRICE'], axis = 1)\n",
    "t = df[t_col]\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, t_train, t_test = train_test_split(x, t, test_size = 0.3, random_state = random_seed)\n",
    "print('================ x_train ================')\n",
    "display(x_train)\n",
    "print('================ t_train ================')\n",
    "display(pd.DataFrame(t_train))\n",
    "print('================ x_test ================')\n",
    "display(x_test)\n",
    "print('================ t_test ================')\n",
    "display(pd.DataFrame(t_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルの学習と評価\n",
    "* 回帰木モデルの学習は，`sklearn`（scikit-learn）の`tree`モジュールにおける`DecisionTreeRegressor`クラスを使う\n",
    "* 回帰木モデルの学習の流れ:\n",
    ">* `DecisionTreeRegressor`クラスを読み込む（インポートする）\n",
    ">* インポートの書式: `from sklearn.tree import DecisionTreeRegressor`\n",
    ">* `DecisionTreeRegressor`クラスのオブジェクトを生成（引数は分類木と同様）し，変数に代入する\n",
    ">* オブジェクト生成の書式: `変数 = DecisionTreeRegressor(max_depth = [最大深さ], random_state = [乱数の種])`\n",
    ">* モデルを学習する\n",
    ">* モデルの学習の書式（これまでのモデルと同様）: `変数.fit(説明変数データ, 目的変数データ)`\n",
    "* 以下のコードで，木の最大深さを4とした回帰木モデルの学習と評価（精度と特徴量重要度を計算）を行う\n",
    "* 内容は第5回「[サンプルノートブック05](https://colab.research.google.com/github/yoshida-nu/lec_datascience/blob/main/doc/datascience_notebook05.ipynb)」の一連の分析と同様（ただし，ここでは予測を省いている）\n",
    "* さらに，`tree`モジュールの`plot_tree`関数で回帰木モデルを描画する（分類木モデルと同様）\n",
    ">* 詳細は第3回「サンプルノートブック03」を参照\n",
    "* 学習と評価を行った結果，良いモデルはできなかったので，さらなるチューニングが必要であるが，今回はここまでとする\n",
    "  \n",
    "**［以下のコードの処理内容］**\n",
    "* 1～2行目: ファイルをDataFrameとして読み込み，変数`df`に代入\n",
    "* 3～4行目: 列の削除，欠損値の対処\n",
    "* 5～7行目: 説明変数と目的変数に分割し，変数`x`と`t`にそれぞれ代入\n",
    "* 8～9行目: 説明変数と目的変数を訓練データ（70％）と検証データ（30％）に分割し，`x_train`, `x_test`, `t_train`, `t_test`にそれぞれ代入\n",
    "* 10行目: `sklearn` (scikit-learn) の`tree`モジュールを読み込む \n",
    "* 11行目: `tree.DecisionTreeClassifier`で，分類木モデルの学習を行うためのオブジェクトを`tree`モジュールの`DecisionTreeClassifier`クラスから生成し，変数`model_tree`に代入\n",
    "* 12行目: 訓練データ（`x_train`と`t_train`）を用いて，`fit`メソッドでモデルの学習を実行\n",
    "* 13行目: `model_tree.score(X = x_train, y = t_train)`で，訓練データに対する精度を計算して変数`score_train`に代入\n",
    "* 14行目: `model_tree.score(X = x_test, y = t_test)`で，テストデータに対する精度を計算して変数`score_test`に代入\n",
    "* 15行目: `print`関数とf-stringを使って，訓練データに対する精度（`score_train`）とテストデータに対する精度（`score_test`）を小数点以下3桁まで表示\n",
    "* 16行目: `display`関数で，`model_tree`オブジェクトの`feature_importances_`属性（特徴量重要度）を表示\n",
    "* 17行目: `pyplot`モジュールの`figure`関数を使って，図のサイズ（高さと幅）を指定\n",
    "* 18行目: `plot_tree`関数で回帰木を描画\n",
    "* 19行目: `show`関数で，それまでに設定した図（回帰木モデル）を実行画面に表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 940,
     "status": "ok",
     "timestamp": 1716691452095,
     "user": {
      "displayName": "Takahiro YOSHIDA",
      "userId": "00096252480874798687"
     },
     "user_tz": -540
    },
    "id": "laB5VCRCdFgU",
    "outputId": "6ca72640-00cc-44b1-f558-eca48c69d90f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練データの精度=0.904 / テストデータの精度=0.293\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>特徴量重要度</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ZN</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INDUS</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHAS</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOX</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RM</th>\n",
       "      <td>0.054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGE</th>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIS</th>\n",
       "      <td>0.073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAD</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAX</th>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PTRATIO</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTAT</th>\n",
       "      <td>0.851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         特徴量重要度\n",
       "ZN        0.000\n",
       "INDUS     0.000\n",
       "CHAS      0.000\n",
       "NOX       0.000\n",
       "RM        0.054\n",
       "AGE       0.006\n",
       "DIS       0.073\n",
       "RAD       0.000\n",
       "TAX       0.017\n",
       "PTRATIO   0.000\n",
       "LSTAT     0.851"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "url = 'https://bit.ly/4hwOUgx'\n",
    "df = pd.read_csv(url)\n",
    "df = df.drop(['CRIME'], axis = 1)\n",
    "df = df.fillna(df.mean())\n",
    "t_col = ['PRICE']\n",
    "x = df.drop(['PRICE'], axis = 1)\n",
    "t = df[t_col]\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, t_train, t_test = train_test_split(x, t, test_size = 0.3, random_state = random_seed)\n",
    "from sklearn import tree\n",
    "model_tree = tree.DecisionTreeRegressor(max_depth = 3, random_state = random_seed)\n",
    "model_tree.fit(x_train, t_train)\n",
    "score_train = model_tree.score(X = x_train, y = t_train)\n",
    "score_test = model_tree.score(X = x_test, y = t_test)\n",
    "print(f'訓練データの精度={score_train:.3f} / テストデータの精度={score_test:.3f}')\n",
    "display(pd.DataFrame(model_tree.feature_importances_, index = x.columns, columns = ['特徴量重要度']))\n",
    "plt.figure(figsize = (12, 3))\n",
    "tree.plot_tree(decision_tree = model_tree, feature_names = list(x.columns))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "pythonv311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
